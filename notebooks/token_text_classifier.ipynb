{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in Data\n",
    "\n",
    "- The AG News dataset consists of 120,000 news articles, each with a title, description & label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(level=logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22586</th>\n",
       "      <td>TiVo, ReplayTV agree to limits (SiliconValley....</td>\n",
       "      <td>SiliconValley.com - The makers of TiVo and Rep...</td>\n",
       "      <td>Sci/Tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118113</th>\n",
       "      <td>Panthers Punter Sauerbrun Arrested for DWI (Re...</td>\n",
       "      <td>Reuters - Carolina Panthers punter\\Todd Sauerb...</td>\n",
       "      <td>Sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20155</th>\n",
       "      <td>European Envoy Visiting Turkey to Assess Situa...</td>\n",
       "      <td>With Turkey #39;s hopes of joining the Europea...</td>\n",
       "      <td>World</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67787</th>\n",
       "      <td>Martha Stewart #39;s Lawyers File Appeal</td>\n",
       "      <td>NEW YORK -- Lawyers for Martha Stewart have to...</td>\n",
       "      <td>Business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92528</th>\n",
       "      <td>Flight attendants union chief wants strike</td>\n",
       "      <td>PITTSBURGH -- The president of the United Stat...</td>\n",
       "      <td>Business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117355</th>\n",
       "      <td>ICANN making available new domain names</td>\n",
       "      <td>The Internet Corporation for Assigned Names an...</td>\n",
       "      <td>Sci/Tech</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    title  \\\n",
       "22586   TiVo, ReplayTV agree to limits (SiliconValley....   \n",
       "118113  Panthers Punter Sauerbrun Arrested for DWI (Re...   \n",
       "20155   European Envoy Visiting Turkey to Assess Situa...   \n",
       "67787            Martha Stewart #39;s Lawyers File Appeal   \n",
       "92528          Flight attendants union chief wants strike   \n",
       "117355            ICANN making available new domain names   \n",
       "\n",
       "                                              description     class  \n",
       "22586   SiliconValley.com - The makers of TiVo and Rep...  Sci/Tech  \n",
       "118113  Reuters - Carolina Panthers punter\\Todd Sauerb...    Sports  \n",
       "20155   With Turkey #39;s hopes of joining the Europea...     World  \n",
       "67787   NEW YORK -- Lawyers for Martha Stewart have to...  Business  \n",
       "92528   PITTSBURGH -- The president of the United Stat...  Business  \n",
       "117355  The Internet Corporation for Assigned Names an...  Sci/Tech  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_df = pd.read_csv('../data/ag_news/train.csv')\n",
    "test_df = pd.read_csv('../data/ag_news/test.csv')\n",
    "\n",
    "train_df.sample(frac=0.00005)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess the data for MXNet\n",
    "\n",
    "The following `TokenPreprocessor` class can:\n",
    "- Tokenize text using spacy\n",
    "- Pad/slice tokenized text to a prespecified length\n",
    "- Convert each token/label to a unique integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import itertools\n",
    "import regex as re\n",
    "\n",
    "\n",
    "class TokenPreprocessor:\n",
    "    def __init__(self, spacy_model, unseen_token=-1, pad_char='<padded>',max_tokens=20, unseen_label=-1):\n",
    "        self.unseen_token=unseen_token\n",
    "        self.pad_char = pad_char\n",
    "        self.max_tokens = max_tokens\n",
    "        self.unseen_label = unseen_label\n",
    "\n",
    "    @staticmethod\n",
    "    def split_utterance(string):\n",
    "        \"\"\"\n",
    "        :param utterance: string\n",
    "        :return: list of string\n",
    "        \"\"\"\n",
    "        string = re.sub(r\"[^A-Za-z0-9(),!?\\'\\`]\", \" \", string)\n",
    "        string = re.sub(r\"\\'s\", \" \\'s\", string)\n",
    "        string = re.sub(r\"\\'ve\", \" \\'ve\", string)\n",
    "        string = re.sub(r\"n\\'t\", \" n\\'t\", string)\n",
    "        string = re.sub(r\"\\'re\", \" \\'re\", string)\n",
    "        string = re.sub(r\"\\'d\", \" \\'d\", string)\n",
    "        string = re.sub(r\"\\'ll\", \" \\'ll\", string)\n",
    "        string = re.sub(r\",\", \" , \", string)\n",
    "        string = re.sub(r\"!\", \" ! \", string)\n",
    "        string = re.sub(r\"\\(\", \" \\( \", string)\n",
    "        string = re.sub(r\"\\)\", \" \\) \", string)\n",
    "        string = re.sub(r\"\\?\", \" \\? \", string)\n",
    "        string = re.sub(r\"\\s{2,}\", \" \", string)\n",
    "        string = string.strip().lower()\n",
    "        return string.split(' ')\n",
    "    \n",
    "    def pad_utterance(self, tokenized_utterance):\n",
    "        \"\"\"\n",
    "        :param utterance: list of string\n",
    "        :param length: desired list length\n",
    "        :return: padded/sliced list\n",
    "        \"\"\"\n",
    "        diff = len(tokenized_utterance) - self.max_tokens\n",
    "        if diff > 0:\n",
    "            return tokenized_utterance[:self.max_tokens]\n",
    "        else:\n",
    "            return tokenized_utterance + [self.pad_char] * -diff\n",
    "\n",
    "    def build_vocab(self, data, depth=1, max_vocab_size=None):\n",
    "        \"\"\"\n",
    "        :param data: list of data\n",
    "        :param depth: depth of data list\n",
    "        :param max_vocab_size:\n",
    "        :return: dict and list mapping data to indices\n",
    "        \"\"\"\n",
    "        if depth >1:\n",
    "            data = list(itertools.chain.from_iterable(data)) # Make list 1D\n",
    "        data_counts = Counter(data)  # Count occurrences of each word in the list\n",
    "\n",
    "        vocabulary_inv = [x[0] for x in data_counts.most_common(max_vocab_size)]\n",
    "        vocabulary = {x: i for i, x in enumerate(vocabulary_inv)}\n",
    "        return vocabulary, vocabulary_inv\n",
    "\n",
    "    def fit(self, utterances, labels):\n",
    "        \"\"\"\n",
    "        :param utterances: list of raw utterances\n",
    "        :param labels: list of raw labels\n",
    "        \"\"\"\n",
    "        split_utterances = [self.split_utterance(utterance) for utterance in utterances]\n",
    "        padded_utterances = [self.pad_utterance(utterance) for utterance in split_utterances]\n",
    "        self.token_to_index, self.index_to_token = self.build_vocab(padded_utterances, depth=2)\n",
    "        self.intent_to_index, self.index_to_intent = self.build_vocab(labels, depth=1)\n",
    "\n",
    "    def transform_utterance(self, utterance):\n",
    "        \"\"\"\n",
    "        :param utterance: raw utterance string\n",
    "        :return: preprocessed utterance\n",
    "        \"\"\"\n",
    "        split_utterance = self.split_utterance(utterance)\n",
    "        padded_utterances = self.pad_utterance(split_utterance)\n",
    "        return [self.token_to_index.get(token, self.unseen_token) for token in padded_utterances]\n",
    "\n",
    "    def transform_label(self, label):\n",
    "        \"\"\"\n",
    "        :param label: raw intent label\n",
    "        :return: indexed intent label\n",
    "        \"\"\"\n",
    "        return self.intent_to_index.get(label, self.unseen_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We fit the preprocessor to the training set. This builds index mappings for the tokens & labels (shown below).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = TokenPreprocessor(spacy_model='en_core_web_sm')\n",
    "\n",
    "preprocessor.fit(train_df['description'].tolist(), train_df['class'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label to index mappings:\t{'Business': 0, 'Sci/Tech': 1, 'Sports': 2, 'World': 3}\n",
      "\n",
      "First 10 token to index mappings:\n",
      "\n",
      "{'the': 0, ',': 1, 'a': 2, 'to': 3, 'of': 4, 'in': 5, 'and': 6, '<padded>': 7, 'on': 8, 'for': 9}\n"
     ]
    }
   ],
   "source": [
    "print(\"Label to index mappings:\\t{}\\n\\nFirst 10 token to index mappings:\\n\\n{}\".\n",
    "      format(preprocessor.intent_to_index, \n",
    "             {k: preprocessor.token_to_index[k] for k in list(preprocessor.token_to_index)[:10]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we preprocess the train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>class</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40227</th>\n",
       "      <td>Resistant Israeli Settlers May Get Prison</td>\n",
       "      <td>JERUSALEM Sept. 26, 2004 - Armed settlers who ...</td>\n",
       "      <td>World</td>\n",
       "      <td>[882, 588, 1049, 1, 102, 1318, 3976, 64, 11344...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101880</th>\n",
       "      <td>Free credit reports to bear ads</td>\n",
       "      <td>Ordered by Congress to give consumers free acc...</td>\n",
       "      <td>Business</td>\n",
       "      <td>[1161, 26, 1034, 3, 568, 890, 388, 737, 3, 40,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108476</th>\n",
       "      <td>Reports: Blasts Rock Madrid Gas Stations</td>\n",
       "      <td>MADRID, Spain - Spanish media are reporting th...</td>\n",
       "      <td>World</td>\n",
       "      <td>[683, 1, 701, 1177, 481, 35, 2025, 14, 24, 215...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93711</th>\n",
       "      <td>Woman  #39;blessed by the holy toast #39;</td>\n",
       "      <td>A half-eaten slice of cheese on toast purporte...</td>\n",
       "      <td>Sci/Tech</td>\n",
       "      <td>[2, 312, 12300, 8754, 4, 5778, 8, 18813, 6163,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36018</th>\n",
       "      <td>Computer Associates to Pay \\$225 Million to Av...</td>\n",
       "      <td>The software giant agreed to pay \\$225 million...</td>\n",
       "      <td>Business</td>\n",
       "      <td>[0, 96, 172, 168, 3, 357, 6142, 94, 3, 1794, 1...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38080</th>\n",
       "      <td>Rival Technologies Vie for 'Green' Car of Tomo...</td>\n",
       "      <td>Reuters - Carmakers presented new-age automobi...</td>\n",
       "      <td>Sci/Tech</td>\n",
       "      <td>[15, 9656, 4344, 19, 2175, 14791, 24, 0, 493, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    title  \\\n",
       "40227           Resistant Israeli Settlers May Get Prison   \n",
       "101880                    Free credit reports to bear ads   \n",
       "108476           Reports: Blasts Rock Madrid Gas Stations   \n",
       "93711           Woman  #39;blessed by the holy toast #39;   \n",
       "36018   Computer Associates to Pay \\$225 Million to Av...   \n",
       "38080   Rival Technologies Vie for 'Green' Car of Tomo...   \n",
       "\n",
       "                                              description     class  \\\n",
       "40227   JERUSALEM Sept. 26, 2004 - Armed settlers who ...     World   \n",
       "101880  Ordered by Congress to give consumers free acc...  Business   \n",
       "108476  MADRID, Spain - Spanish media are reporting th...     World   \n",
       "93711   A half-eaten slice of cheese on toast purporte...  Sci/Tech   \n",
       "36018   The software giant agreed to pay \\$225 million...  Business   \n",
       "38080   Reuters - Carmakers presented new-age automobi...  Sci/Tech   \n",
       "\n",
       "                                                        X  Y  \n",
       "40227   [882, 588, 1049, 1, 102, 1318, 3976, 64, 11344...  3  \n",
       "101880  [1161, 26, 1034, 3, 568, 890, 388, 737, 3, 40,...  0  \n",
       "108476  [683, 1, 701, 1177, 481, 35, 2025, 14, 24, 215...  3  \n",
       "93711   [2, 312, 12300, 8754, 4, 5778, 8, 18813, 6163,...  1  \n",
       "36018   [0, 96, 172, 168, 3, 357, 6142, 94, 3, 1794, 1...  0  \n",
       "38080   [15, 9656, 4344, 19, 2175, 14791, 24, 0, 493, ...  1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['X'] = train_df['description'].apply(lambda x: preprocessor.transform_utterance(x))\n",
    "train_df['Y'] = train_df['class'].apply(lambda x: preprocessor.transform_label(x))\n",
    "\n",
    "test_df['X'] = test_df['description'].apply(lambda x: preprocessor.transform_utterance(x))\n",
    "test_df['Y'] = test_df['class'].apply(lambda x: preprocessor.transform_label(x))\n",
    "\n",
    "train_df.sample(frac=0.00005)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally lets use the preprocessor to transform some new text. Notice the padding to ensure constant input length & the handling of unknown words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The news looks bad today. ==> [0, 134, 1176, 1378, 78, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7]\n",
      "MXNet is awesome. No really... ==>[-1, 17, 18311, 100, 1983, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7]\n"
     ]
    }
   ],
   "source": [
    "print(\"The news looks bad today. ==> {}\".format(preprocessor.transform_utterance(\"The news looks bad today.\")))\n",
    "print(\"MXNet is awesome. No really... ==>{}\".format(preprocessor.transform_utterance(\"MXNet is awesome. No really...\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49705\n"
     ]
    }
   ],
   "source": [
    "print(len(preprocessor.token_to_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Data Iterators\n",
    "\n",
    "Next we use the preprocessor to transform the data & labels, convert the output to numpy arrays and build mxnet data iterators to feed batches to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "import numpy as np\n",
    "\n",
    "X_train = np.array(train_df['X'].tolist())\n",
    "Y_train = np.array(train_df['Y'].tolist())\n",
    "\n",
    "X_test = np.array(test_df['X'].tolist())\n",
    "Y_test = np.array(test_df['Y'].tolist())\n",
    "\n",
    "batch_n=120\n",
    "\n",
    "train_iter = mx.io.NDArrayIter(data=X_train, label=Y_train, batch_size=batch_n, shuffle=True)\n",
    "test_iter = mx.io.NDArrayIter(data=X_test, label=Y_test, batch_size=batch_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets take a look at the first batch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 0\n",
      "X:\n",
      "[\n",
      "[[4.2100e+02 6.4800e+02 1.7200e+02 ... 1.4440e+04 3.4000e+02 1.7000e+01]\n",
      " [3.8388e+04 1.9190e+03 4.4000e+01 ... 1.0000e+00 2.3300e+02 8.0000e+00]\n",
      " [3.0020e+03 1.0000e+01 1.5000e+01 ... 4.5360e+03 3.0000e+00 4.5190e+03]\n",
      " ...\n",
      " [3.9550e+03 6.0000e+00 9.4110e+03 ... 1.6400e+02 3.0000e+00 7.6000e+01]\n",
      " [2.8000e+01 2.9100e+03 2.4470e+03 ... 7.0000e+00 7.0000e+00 7.0000e+00]\n",
      " [1.4900e+02 4.8700e+02 3.9940e+03 ... 6.5000e+01 9.5270e+03 5.0000e+00]]\n",
      "<NDArray 120x20 @cpu(0)>]\n",
      " Y:\n",
      "[\n",
      "[1. 1. 1. 0. 2. 0. 0. 3. 3. 2. 1. 3. 3. 3. 2. 2. 3. 1. 3. 3. 1. 2. 0. 1.\n",
      " 0. 3. 3. 1. 0. 1. 1. 2. 1. 1. 0. 1. 0. 0. 2. 2. 0. 3. 2. 3. 2. 1. 3. 3.\n",
      " 1. 1. 3. 0. 3. 0. 0. 1. 1. 3. 3. 3. 2. 3. 1. 2. 1. 0. 1. 1. 1. 2. 3. 3.\n",
      " 2. 2. 3. 3. 3. 3. 0. 2. 1. 2. 1. 3. 3. 1. 3. 1. 2. 1. 1. 3. 1. 0. 1. 2.\n",
      " 0. 3. 0. 0. 3. 3. 1. 1. 2. 3. 1. 0. 1. 1. 2. 3. 0. 0. 0. 0. 1. 0. 2. 2.]\n",
      "<NDArray 120 @cpu(0)>]\n"
     ]
    }
   ],
   "source": [
    "for i, batch in enumerate(train_iter):\n",
    "    if i < 1:\n",
    "        print(\"\\nBatch {}\\nX:\\n{}\\n Y:\\n{}\".format(i, batch.data, batch.label))\n",
    "train_iter.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the model symbol\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sym_gen(sentence_size, num_embed, vocab_size, num_label, filter_list, num_filter, dropout):\n",
    "    \"\"\"\n",
    "    :param sentence_size: number of tokens per utterance\n",
    "    :param num_embed: embedding size for each token\n",
    "    :param vocab_size: number of unique tokens in the training set\n",
    "    :param num_label: number of output classes \n",
    "    :param filter_list: list of filter heights\n",
    "    :param num_filter: number of each filter height\n",
    "    :return: network symbol\n",
    "    \"\"\"\n",
    "    input_x = mx.sym.Variable('data')\n",
    "    input_y = mx.sym.Variable('softmax_label')\n",
    "\n",
    "    embed_layer = mx.sym.Embedding(data=input_x, input_dim=vocab_size, output_dim=num_embed)\n",
    "    \n",
    "    # reshape to (batches, channels, height, width)\n",
    "    conv_input = mx.sym.reshape(data=embed_layer, shape=(0, 1, sentence_size, num_embed))\n",
    "\n",
    "    # create convolution + (max) pooling layer for each filter operation\n",
    "    pooled_outputs = []\n",
    "    for i, filter_size in enumerate(filter_list):\n",
    "        convi = mx.sym.Convolution(data=conv_input, kernel=(filter_size, num_embed), num_filter=num_filter)\n",
    "        relui = mx.sym.Activation(data=convi, act_type='relu')\n",
    "        pooli = mx.sym.Pooling(data=relui, pool_type='max', kernel=(sentence_size - filter_size + 1, 1), stride=(1,1))\n",
    "        pooled_outputs.append(pooli)\n",
    "\n",
    "    # concatenate pooled outputs\n",
    "    concat = mx.sym.Concat(*pooled_outputs, dim=1)\n",
    "    \n",
    "    # reshape to (batches, num filters)\n",
    "    h_pool = mx.sym.reshape(data=concat, shape=(0, -1))\n",
    "    \n",
    "    h_drop = mx.sym.Dropout(data=h_pool, p=dropout)\n",
    "    \n",
    "    fc = mx.sym.FullyConnected(data=h_drop, num_hidden=num_label)\n",
    "\n",
    "    return mx.sym.SoftmaxOutput(data=fc, label=input_y, name='softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbol = sym_gen(sentence_size=preprocessor.max_tokens, \n",
    "                 num_embed=16, \n",
    "                 vocab_size=len(preprocessor.token_to_index), \n",
    "                 num_label=len(preprocessor.intent_to_index),\n",
    "                 filter_list=[3, 4, 5], \n",
    "                 num_filter=100, \n",
    "                 dropout=0.85)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model\n",
    "\n",
    "- State of the art test accuracy ~ 92%\n",
    "- Within 3 epochs, training on a cpu, discarding any tokens above 20 we come within ~3%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch[0] Train-accuracy=0.731250\n",
      "INFO:root:Epoch[0] Time cost=23.463\n",
      "INFO:root:Epoch[0] Validation-accuracy=0.880599\n",
      "INFO:root:Epoch[1] Train-accuracy=0.887333\n",
      "INFO:root:Epoch[1] Time cost=32.151\n",
      "INFO:root:Epoch[1] Validation-accuracy=0.891276\n",
      "INFO:root:Epoch[2] Train-accuracy=0.908992\n",
      "INFO:root:Epoch[2] Time cost=32.255\n",
      "INFO:root:Epoch[2] Validation-accuracy=0.891276\n"
     ]
    }
   ],
   "source": [
    "module = mx.mod.Module(symbol)\n",
    "\n",
    "module.fit(train_data=train_iter,\n",
    "           eval_data=test_iter,\n",
    "           eval_metric=mx.metric.Accuracy(),\n",
    "           optimizer='Adam',\n",
    "           optimizer_params={'learning_rate': 0.001},\n",
    "           initializer=mx.initializer.Uniform(0.1),\n",
    "           num_epoch=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(utterance, preprocessor, module):\n",
    "    \"\"\"\n",
    "    :param module: trained mxnet module\n",
    "    :param preprocessor: fit preprocessor\n",
    "    :param utterance: raw string for prediction\n",
    "    :return: list of tuple\n",
    "    \"\"\"\n",
    "    preprocessed_utterance = preprocessor.transform_utterance(utterance)\n",
    "    numpy_utterance = np.array([preprocessed_utterance])\n",
    "    pred_iter = mx.io.NDArrayIter(data=numpy_utterance, label=np.array([0]), batch_size=1)\n",
    "    predicted_probabilities = module.predict(pred_iter).asnumpy().tolist()[0]\n",
    "    class_preds = [(preprocessor.index_to_intent[i], v) for i, v in enumerate(predicted_probabilities)]\n",
    "    return class_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text:\n",
      "\n",
      "Reuters - With oil prices close to  #36;50 a\\barrel, the Bush administration is set to allow oil refineries\\to borrow crude from the government's emergency petroleum\\stockpile to make up for supplies disrupted by Hurricane Ivan,\\a congressional source briefed on the pending decision told\\Reuters on Thursday.\n",
      "\n",
      "Label:\n",
      "\n",
      "Business\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "idx = random.randint(1,test_df.shape[0])\n",
    "utterance = test_df.iloc[idx].description\n",
    "label = test_df.iloc[idx]['class']\n",
    "\n",
    "print(\"Text:\\n\\n{}\\n\\nLabel:\\n\\n{}\".format(utterance, label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Business', 0.952357292175293),\n",
       " ('Sci/Tech', 0.00678549287840724),\n",
       " ('Sports', 4.061499930685386e-05),\n",
       " ('World', 0.04081658646464348)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_preds = predict(utterance, preprocessor, module)\n",
    "class_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usually we want the highest confidence prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Business', 0.952357292175293)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "max(class_preds,key=itemgetter(1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3_mxnet",
   "language": "python",
   "name": "python3_mxnet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
