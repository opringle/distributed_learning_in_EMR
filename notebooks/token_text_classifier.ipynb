{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in Data\n",
    "\n",
    "- The AG News dataset consists of 120,000 news articles, each with a title, description & label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(level=logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>103478</th>\n",
       "      <td>Wade Boggs Leads Hall of Fame Candidates (AP)</td>\n",
       "      <td>AP - Wade Boggs might have to get used to a ne...</td>\n",
       "      <td>Sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95460</th>\n",
       "      <td>Blair, Chirac try to put Iraq war behind them ...</td>\n",
       "      <td>AFP - British Prime Minister Tony Blair and Fr...</td>\n",
       "      <td>World</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107878</th>\n",
       "      <td>Blue-ray mass market move</td>\n",
       "      <td>Singulus Technologies will begin selling machi...</td>\n",
       "      <td>Sci/Tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47444</th>\n",
       "      <td>Transactions</td>\n",
       "      <td>BASKETBALL Cleveland (NBA): Signed G Lucious H...</td>\n",
       "      <td>Sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102472</th>\n",
       "      <td>Dollar Struggles to Extend Recovery (Reuters)</td>\n",
       "      <td>Reuters - The dollar struggled on Tuesday to e...</td>\n",
       "      <td>Business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96029</th>\n",
       "      <td>Trade Negotiators Get Technical at WTO</td>\n",
       "      <td>Negotiators gathered Friday at the World Trade...</td>\n",
       "      <td>Business</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    title  \\\n",
       "103478      Wade Boggs Leads Hall of Fame Candidates (AP)   \n",
       "95460   Blair, Chirac try to put Iraq war behind them ...   \n",
       "107878                          Blue-ray mass market move   \n",
       "47444                                        Transactions   \n",
       "102472      Dollar Struggles to Extend Recovery (Reuters)   \n",
       "96029              Trade Negotiators Get Technical at WTO   \n",
       "\n",
       "                                              description     class  \n",
       "103478  AP - Wade Boggs might have to get used to a ne...    Sports  \n",
       "95460   AFP - British Prime Minister Tony Blair and Fr...     World  \n",
       "107878  Singulus Technologies will begin selling machi...  Sci/Tech  \n",
       "47444   BASKETBALL Cleveland (NBA): Signed G Lucious H...    Sports  \n",
       "102472  Reuters - The dollar struggled on Tuesday to e...  Business  \n",
       "96029   Negotiators gathered Friday at the World Trade...  Business  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_df = pd.read_csv('../data/ag_news/train.csv')\n",
    "test_df = pd.read_csv('../data/ag_news/test.csv')\n",
    "\n",
    "train_df.sample(frac=0.00005)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess the data for MXNet\n",
    "\n",
    "The following `TokenPreprocessor` class can:\n",
    "- Tokenize text using regex\n",
    "- Pad/slice tokenized text to a prespecified length\n",
    "- Convert each token/label to a unique integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import itertools\n",
    "import regex as re\n",
    "\n",
    "\n",
    "class TokenPreprocessor:\n",
    "    def __init__(self, unseen_token=-1, pad_char='<padded>',max_tokens=20, unseen_label=-1):\n",
    "        self.unseen_token=unseen_token\n",
    "        self.pad_char = pad_char\n",
    "        self.max_tokens = max_tokens\n",
    "        self.unseen_label = unseen_label\n",
    "\n",
    "    @staticmethod\n",
    "    def split_utterance(string):\n",
    "        \"\"\"\n",
    "        :param utterance: string\n",
    "        :return: list of string\n",
    "        \"\"\"\n",
    "        string = re.sub(r\"[^A-Za-z0-9(),!?\\'\\`]\", \" \", string)\n",
    "        string = re.sub(r\"\\'s\", \" \\'s\", string)\n",
    "        string = re.sub(r\"\\'ve\", \" \\'ve\", string)\n",
    "        string = re.sub(r\"n\\'t\", \" n\\'t\", string)\n",
    "        string = re.sub(r\"\\'re\", \" \\'re\", string)\n",
    "        string = re.sub(r\"\\'d\", \" \\'d\", string)\n",
    "        string = re.sub(r\"\\'ll\", \" \\'ll\", string)\n",
    "        string = re.sub(r\",\", \" , \", string)\n",
    "        string = re.sub(r\"!\", \" ! \", string)\n",
    "        string = re.sub(r\"\\(\", \" \\( \", string)\n",
    "        string = re.sub(r\"\\)\", \" \\) \", string)\n",
    "        string = re.sub(r\"\\?\", \" \\? \", string)\n",
    "        string = re.sub(r\"\\s{2,}\", \" \", string)\n",
    "        string = string.strip().lower()\n",
    "        return string.split(' ')\n",
    "    \n",
    "    def pad_utterance(self, tokenized_utterance):\n",
    "        \"\"\"\n",
    "        :param utterance: list of string\n",
    "        :param length: desired list length\n",
    "        :return: padded/sliced list\n",
    "        \"\"\"\n",
    "        diff = len(tokenized_utterance) - self.max_tokens\n",
    "        if diff > 0:\n",
    "            return tokenized_utterance[:self.max_tokens]\n",
    "        else:\n",
    "            return tokenized_utterance + [self.pad_char] * -diff\n",
    "\n",
    "    def build_vocab(self, data, depth=1, max_vocab_size=None):\n",
    "        \"\"\"\n",
    "        :param data: list of data\n",
    "        :param depth: depth of data list\n",
    "        :param max_vocab_size:\n",
    "        :return: dict and list mapping data to indices\n",
    "        \"\"\"\n",
    "        if depth >1:\n",
    "            data = list(itertools.chain.from_iterable(data)) # Make list 1D\n",
    "        data_counts = Counter(data)  # Count occurrences of each word in the list\n",
    "\n",
    "        vocabulary_inv = [x[0] for x in data_counts.most_common(max_vocab_size)]\n",
    "        vocabulary = {x: i for i, x in enumerate(vocabulary_inv)}\n",
    "        return vocabulary, vocabulary_inv\n",
    "\n",
    "    def fit(self, utterances, labels):\n",
    "        \"\"\"\n",
    "        :param utterances: list of raw utterances\n",
    "        :param labels: list of raw labels\n",
    "        \"\"\"\n",
    "        split_utterances = [self.split_utterance(utterance) for utterance in utterances]\n",
    "        padded_utterances = [self.pad_utterance(utterance) for utterance in split_utterances]\n",
    "        self.token_to_index, self.index_to_token = self.build_vocab(padded_utterances, depth=2)\n",
    "        self.intent_to_index, self.index_to_intent = self.build_vocab(labels, depth=1)\n",
    "\n",
    "    def transform_utterance(self, utterance):\n",
    "        \"\"\"\n",
    "        :param utterance: raw utterance string\n",
    "        :return: preprocessed utterance\n",
    "        \"\"\"\n",
    "        split_utterance = self.split_utterance(utterance)\n",
    "        padded_utterances = self.pad_utterance(split_utterance)\n",
    "        return [self.token_to_index.get(token, self.unseen_token) for token in padded_utterances]\n",
    "\n",
    "    def transform_label(self, label):\n",
    "        \"\"\"\n",
    "        :param label: raw intent label\n",
    "        :return: indexed intent label\n",
    "        \"\"\"\n",
    "        return self.intent_to_index.get(label, self.unseen_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We fit the preprocessor to the training set. This builds index mappings for the tokens & labels (shown below).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = TokenPreprocessor()\n",
    "\n",
    "preprocessor.fit(train_df['description'].tolist(), train_df['class'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label to index mappings:\t{'Business': 0, 'Sci/Tech': 1, 'Sports': 2, 'World': 3}\n",
      "\n",
      "First 10 token to index mappings:\n",
      "\n",
      "{'the': 0, ',': 1, 'a': 2, 'to': 3, 'of': 4, 'in': 5, 'and': 6, '<padded>': 7, 'on': 8, 'for': 9}\n"
     ]
    }
   ],
   "source": [
    "print(\"Label to index mappings:\\t{}\\n\\nFirst 10 token to index mappings:\\n\\n{}\".\n",
    "      format(preprocessor.intent_to_index, \n",
    "             {k: preprocessor.token_to_index[k] for k in list(preprocessor.token_to_index)[:10]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we preprocess the train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>class</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>109413</th>\n",
       "      <td>Bryant Comments Sour Malone on Lakers (AP)</td>\n",
       "      <td>AP - Karl Malone has ruled out a return to the...</td>\n",
       "      <td>Sports</td>\n",
       "      <td>[28, 6712, 7007, 16, 1020, 70, 2, 590, 3, 0, 3...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49985</th>\n",
       "      <td>Genetic Study of Lice Hints At Clash of Archai...</td>\n",
       "      <td>Scientists unraveling the genetic history of h...</td>\n",
       "      <td>Sci/Tech</td>\n",
       "      <td>[396, 20245, 0, 4334, 663, 4, 326, 13485, 34, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63685</th>\n",
       "      <td>BMW #39;s Rolls-Royce unit head resigns; CFO n...</td>\n",
       "      <td>LONDON, October 18 (newratings.com) - German a...</td>\n",
       "      <td>Business</td>\n",
       "      <td>[119, 1, 348, 458, 10, 2190, 80, 12, 565, 3830...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30261</th>\n",
       "      <td>Mobile Phones Cleared for Takeoff</td>\n",
       "      <td>Cell phones and wireless devices pass Airbus's...</td>\n",
       "      <td>Sci/Tech</td>\n",
       "      <td>[816, 821, 6, 280, 753, 1352, 1944, 23, 11743,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106998</th>\n",
       "      <td>Microsoft squeezed by contract law</td>\n",
       "      <td>Microsoft has been dropped from a \\$3.6m contr...</td>\n",
       "      <td>Sci/Tech</td>\n",
       "      <td>[82, 16, 63, 1051, 29, 2, 137, 21767, 490, 5, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14179</th>\n",
       "      <td>Fires at homes in Waterford Township, Detroit ...</td>\n",
       "      <td>A police officer in this Detroit suburb died w...</td>\n",
       "      <td>Business</td>\n",
       "      <td>[2, 226, 957, 5, 48, 845, 10617, 743, 18, 30, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    title  \\\n",
       "109413         Bryant Comments Sour Malone on Lakers (AP)   \n",
       "49985   Genetic Study of Lice Hints At Clash of Archai...   \n",
       "63685   BMW #39;s Rolls-Royce unit head resigns; CFO n...   \n",
       "30261                   Mobile Phones Cleared for Takeoff   \n",
       "106998                 Microsoft squeezed by contract law   \n",
       "14179   Fires at homes in Waterford Township, Detroit ...   \n",
       "\n",
       "                                              description     class  \\\n",
       "109413  AP - Karl Malone has ruled out a return to the...    Sports   \n",
       "49985   Scientists unraveling the genetic history of h...  Sci/Tech   \n",
       "63685   LONDON, October 18 (newratings.com) - German a...  Business   \n",
       "30261   Cell phones and wireless devices pass Airbus's...  Sci/Tech   \n",
       "106998  Microsoft has been dropped from a \\$3.6m contr...  Sci/Tech   \n",
       "14179   A police officer in this Detroit suburb died w...  Business   \n",
       "\n",
       "                                                        X  Y  \n",
       "109413  [28, 6712, 7007, 16, 1020, 70, 2, 590, 3, 0, 3...  2  \n",
       "49985   [396, 20245, 0, 4334, 663, 4, 326, 13485, 34, ...  1  \n",
       "63685   [119, 1, 348, 458, 10, 2190, 80, 12, 565, 3830...  0  \n",
       "30261   [816, 821, 6, 280, 753, 1352, 1944, 23, 11743,...  1  \n",
       "106998  [82, 16, 63, 1051, 29, 2, 137, 21767, 490, 5, ...  1  \n",
       "14179   [2, 226, 957, 5, 48, 845, 10617, 743, 18, 30, ...  0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['X'] = train_df['description'].apply(lambda x: preprocessor.transform_utterance(x))\n",
    "train_df['Y'] = train_df['class'].apply(lambda x: preprocessor.transform_label(x))\n",
    "\n",
    "test_df['X'] = test_df['description'].apply(lambda x: preprocessor.transform_utterance(x))\n",
    "test_df['Y'] = test_df['class'].apply(lambda x: preprocessor.transform_label(x))\n",
    "\n",
    "train_df.sample(frac=0.00005)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally lets use the preprocessor to transform some new text. Notice the padding to ensure constant input length & the handling of unknown words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-1, 17, 18311, 100, 1983, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessor.transform_utterance(\"MXNet is awesome. No really...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49705\n"
     ]
    }
   ],
   "source": [
    "print(len(preprocessor.token_to_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Data Iterators\n",
    "\n",
    "Next we use the preprocessor to transform the data & labels, convert the output to numpy arrays and build mxnet data iterators to feed batches to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "import numpy as np\n",
    "\n",
    "X_train = np.array(train_df['X'].tolist())\n",
    "Y_train = np.array(train_df['Y'].tolist())\n",
    "\n",
    "X_test = np.array(test_df['X'].tolist())\n",
    "Y_test = np.array(test_df['Y'].tolist())\n",
    "\n",
    "batch_n=120\n",
    "\n",
    "train_iter = mx.io.NDArrayIter(data=X_train, label=Y_train, batch_size=batch_n, shuffle=True)\n",
    "test_iter = mx.io.NDArrayIter(data=X_test, label=Y_test, batch_size=batch_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets take a look at the first batch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 0\n",
      "X:\n",
      "[\n",
      "[[4.2100e+02 6.4800e+02 1.7200e+02 ... 1.4440e+04 3.4000e+02 1.7000e+01]\n",
      " [3.8388e+04 1.9190e+03 4.4000e+01 ... 1.0000e+00 2.3300e+02 8.0000e+00]\n",
      " [3.0020e+03 1.0000e+01 1.5000e+01 ... 4.5360e+03 3.0000e+00 4.5190e+03]\n",
      " ...\n",
      " [3.9550e+03 6.0000e+00 9.4110e+03 ... 1.6400e+02 3.0000e+00 7.6000e+01]\n",
      " [2.8000e+01 2.9100e+03 2.4470e+03 ... 7.0000e+00 7.0000e+00 7.0000e+00]\n",
      " [1.4900e+02 4.8700e+02 3.9940e+03 ... 6.5000e+01 9.5270e+03 5.0000e+00]]\n",
      "<NDArray 120x20 @cpu(0)>]\n",
      " Y:\n",
      "[\n",
      "[1. 1. 1. 0. 2. 0. 0. 3. 3. 2. 1. 3. 3. 3. 2. 2. 3. 1. 3. 3. 1. 2. 0. 1.\n",
      " 0. 3. 3. 1. 0. 1. 1. 2. 1. 1. 0. 1. 0. 0. 2. 2. 0. 3. 2. 3. 2. 1. 3. 3.\n",
      " 1. 1. 3. 0. 3. 0. 0. 1. 1. 3. 3. 3. 2. 3. 1. 2. 1. 0. 1. 1. 1. 2. 3. 3.\n",
      " 2. 2. 3. 3. 3. 3. 0. 2. 1. 2. 1. 3. 3. 1. 3. 1. 2. 1. 1. 3. 1. 0. 1. 2.\n",
      " 0. 3. 0. 0. 3. 3. 1. 1. 2. 3. 1. 0. 1. 1. 2. 3. 0. 0. 0. 0. 1. 0. 2. 2.]\n",
      "<NDArray 120 @cpu(0)>]\n"
     ]
    }
   ],
   "source": [
    "for i, batch in enumerate(train_iter):\n",
    "    if i < 1:\n",
    "        print(\"\\nBatch {}\\nX:\\n{}\\n Y:\\n{}\".format(i, batch.data, batch.label))\n",
    "train_iter.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the model symbol\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sym_gen(sentence_size, num_embed, vocab_size, num_label, filter_list, num_filter, dropout):\n",
    "    \"\"\"\n",
    "    :param sentence_size: number of tokens per utterance\n",
    "    :param num_embed: embedding size for each token\n",
    "    :param vocab_size: number of unique tokens in the training set\n",
    "    :param num_label: number of output classes \n",
    "    :param filter_list: list of filter heights\n",
    "    :param num_filter: number of each filter height\n",
    "    :return: network symbol\n",
    "    \"\"\"\n",
    "    input_x = mx.sym.Variable('data')\n",
    "    input_y = mx.sym.Variable('softmax_label')\n",
    "\n",
    "    embed_layer = mx.sym.Embedding(data=input_x, input_dim=vocab_size, output_dim=num_embed)\n",
    "    \n",
    "    # reshape to (batches, channels, height, width)\n",
    "    conv_input = mx.sym.reshape(data=embed_layer, shape=(0, 1, sentence_size, num_embed))\n",
    "\n",
    "    # create convolution + (max) pooling layer for each filter operation\n",
    "    pooled_outputs = []\n",
    "    for i, filter_size in enumerate(filter_list):\n",
    "        convi = mx.sym.Convolution(data=conv_input, \n",
    "                                   kernel=(filter_size, num_embed), \n",
    "                                   num_filter=num_filter)\n",
    "        relui = mx.sym.Activation(data=convi, act_type='relu')\n",
    "        pooli = mx.sym.Pooling(data=relui, \n",
    "                               pool_type='max', \n",
    "                               kernel=(sentence_size - filter_size + 1, 1), \n",
    "                               stride=(1,1))\n",
    "        pooled_outputs.append(pooli)\n",
    "\n",
    "    # concatenate pooled outputs\n",
    "    concat = mx.sym.Concat(*pooled_outputs, dim=1)\n",
    "    \n",
    "    # reshape to (batches, num filters)\n",
    "    h_pool = mx.sym.reshape(data=concat, shape=(0, -1))\n",
    "    \n",
    "    h_drop = mx.sym.Dropout(data=h_pool, p=dropout)\n",
    "    \n",
    "    fc = mx.sym.FullyConnected(data=h_drop, num_hidden=num_label)\n",
    "\n",
    "    return mx.sym.SoftmaxOutput(data=fc, label=input_y, name='softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbol = sym_gen(sentence_size=preprocessor.max_tokens, \n",
    "                 num_embed=16, \n",
    "                 vocab_size=len(preprocessor.token_to_index), \n",
    "                 num_label=len(preprocessor.intent_to_index),\n",
    "                 filter_list=[3, 4, 5], \n",
    "                 num_filter=100, \n",
    "                 dropout=0.85)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model\n",
    "\n",
    "- State of the art test accuracy ~ 92%\n",
    "- Within 3 epochs, training on a cpu, discarding any tokens above 20 we come within ~3%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch[0] Train-accuracy=0.731250\n",
      "INFO:root:Epoch[0] Time cost=22.890\n",
      "INFO:root:Epoch[0] Validation-accuracy=0.880599\n",
      "INFO:root:Epoch[1] Train-accuracy=0.887333\n",
      "INFO:root:Epoch[1] Time cost=31.167\n",
      "INFO:root:Epoch[1] Validation-accuracy=0.891276\n",
      "INFO:root:Epoch[2] Train-accuracy=0.908992\n",
      "INFO:root:Epoch[2] Time cost=32.135\n",
      "INFO:root:Epoch[2] Validation-accuracy=0.891276\n"
     ]
    }
   ],
   "source": [
    "module = mx.mod.Module(symbol)\n",
    "\n",
    "module.fit(train_data=train_iter,\n",
    "           eval_data=test_iter,\n",
    "           eval_metric=mx.metric.Accuracy(),\n",
    "           optimizer='Adam',\n",
    "           optimizer_params={'learning_rate': 0.001},\n",
    "           initializer=mx.initializer.Uniform(0.1),\n",
    "           num_epoch=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(utterance, preprocessor, module):\n",
    "    \"\"\"\n",
    "    :param module: trained mxnet module\n",
    "    :param preprocessor: fit preprocessor\n",
    "    :param utterance: raw string for prediction\n",
    "    :return: list of tuple\n",
    "    \"\"\"\n",
    "    preprocessed_utterance = preprocessor.transform_utterance(utterance)\n",
    "    numpy_utterance = np.array([preprocessed_utterance])\n",
    "    pred_iter = mx.io.NDArrayIter(data=numpy_utterance, label=np.array([0]), batch_size=1)\n",
    "    predicted_probabilities = module.predict(pred_iter).asnumpy().tolist()[0]\n",
    "    class_preds = [(preprocessor.index_to_intent[i], v) \n",
    "                   for i, v in enumerate(predicted_probabilities)]\n",
    "    return class_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text:\n",
      "\n",
      "By PAUL GEITNER    BRUSSELS, Belgium (AP) -- Europeans eat less of the most dangerous, cholesterol-raising fats than Americans do and the amount is decreasing, according to a report released Wednesday by the European Food Safety Authority.    Scientists at the European Food Safety authority declined to say whether the EU should follow the United States' lead and require special labels on margarine, chips, cookies, fries and other potential sources of trans fatty acids...\n",
      "\n",
      "Label:\n",
      "\n",
      "Sci/Tech\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "idx = random.randint(1,test_df.shape[0])\n",
    "utterance = test_df.iloc[idx].description\n",
    "label = test_df.iloc[idx]['class']\n",
    "\n",
    "print(\"Text:\\n\\n{}\\n\\nLabel:\\n\\n{}\".format(utterance, label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Business', 0.035319454967975616),\n",
       " ('Sci/Tech', 0.8979151248931885),\n",
       " ('Sports', 0.02296283096075058),\n",
       " ('World', 0.043802473694086075)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_preds = predict(utterance, preprocessor, module)\n",
    "class_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usually we want the highest confidence prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Sci/Tech', 0.8979151248931885)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "max(class_preds,key=itemgetter(1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3_mxnet",
   "language": "python",
   "name": "python3_mxnet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
