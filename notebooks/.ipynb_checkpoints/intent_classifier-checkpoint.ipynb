{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fears for T N pension after talks</td>\n",
       "      <td>Unions representing workers at Turner   Newall...</td>\n",
       "      <td>Business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Race is On: Second Private Team Sets Launc...</td>\n",
       "      <td>SPACE.com - TORONTO, Canada -- A second\\team o...</td>\n",
       "      <td>Sci/Tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ky. Company Wins Grant to Study Peptides (AP)</td>\n",
       "      <td>AP - A company founded by a chemistry research...</td>\n",
       "      <td>Sci/Tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Prediction Unit Helps Forecast Wildfires (AP)</td>\n",
       "      <td>AP - It's barely dawn when Mike Fitzpatrick st...</td>\n",
       "      <td>Sci/Tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Calif. Aims to Limit Farm-Related Smog (AP)</td>\n",
       "      <td>AP - Southern California's smog-fighting agenc...</td>\n",
       "      <td>Sci/Tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Open Letter Against British Copyright Indoctri...</td>\n",
       "      <td>The British Department for Education and Skill...</td>\n",
       "      <td>Sci/Tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Loosing the War on Terrorism</td>\n",
       "      <td>\\\\\"Sven Jaschan, self-confessed author of the ...</td>\n",
       "      <td>Sci/Tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>FOAFKey: FOAF, PGP, Key Distribution, and Bloo...</td>\n",
       "      <td>\\\\FOAF/LOAF  and bloom filters have a lot of i...</td>\n",
       "      <td>Sci/Tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>E-mail scam targets police chief</td>\n",
       "      <td>Wiltshire Police warns about \"phishing\" after ...</td>\n",
       "      <td>Sci/Tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Card fraud unit nets 36,000 cards</td>\n",
       "      <td>In its first two years, the UK's dedicated car...</td>\n",
       "      <td>Sci/Tech</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0                  Fears for T N pension after talks   \n",
       "1  The Race is On: Second Private Team Sets Launc...   \n",
       "2      Ky. Company Wins Grant to Study Peptides (AP)   \n",
       "3      Prediction Unit Helps Forecast Wildfires (AP)   \n",
       "4        Calif. Aims to Limit Farm-Related Smog (AP)   \n",
       "5  Open Letter Against British Copyright Indoctri...   \n",
       "6                       Loosing the War on Terrorism   \n",
       "7  FOAFKey: FOAF, PGP, Key Distribution, and Bloo...   \n",
       "8                   E-mail scam targets police chief   \n",
       "9                  Card fraud unit nets 36,000 cards   \n",
       "\n",
       "                                         description     class  \n",
       "0  Unions representing workers at Turner   Newall...  Business  \n",
       "1  SPACE.com - TORONTO, Canada -- A second\\team o...  Sci/Tech  \n",
       "2  AP - A company founded by a chemistry research...  Sci/Tech  \n",
       "3  AP - It's barely dawn when Mike Fitzpatrick st...  Sci/Tech  \n",
       "4  AP - Southern California's smog-fighting agenc...  Sci/Tech  \n",
       "5  The British Department for Education and Skill...  Sci/Tech  \n",
       "6  \\\\\"Sven Jaschan, self-confessed author of the ...  Sci/Tech  \n",
       "7  \\\\FOAF/LOAF  and bloom filters have a lot of i...  Sci/Tech  \n",
       "8  Wiltshire Police warns about \"phishing\" after ...  Sci/Tech  \n",
       "9  In its first two years, the UK's dedicated car...  Sci/Tech  "
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_df = pd.read_csv('../data/ag_news/train.csv')[:100]\n",
    "test_df = pd.read_csv('../data/ag_news/test.csv')[:30]\n",
    "\n",
    "test_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess the data for MXNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import itertools\n",
    "import spacy\n",
    "\n",
    "class TokenPreprocessor():\n",
    "    def __init__(self, spacy_model, unseen_token=-1, pad_char='<padded>',max_tokens=20, unseen_label=-1):\n",
    "        self.unseen_token=unseen_token\n",
    "        self.pad_char = pad_char\n",
    "        self.max_tokens = max_tokens\n",
    "        self.unseen_label = unseen_label      \n",
    "        self.nlp = spacy.load(spacy_model)\n",
    "\n",
    "    def split_utterance(self, utterance):\n",
    "        \"\"\"\n",
    "        :param utterance: string\n",
    "        :return: list of string\n",
    "        \"\"\"\n",
    "        doc = self.nlp(utterance)\n",
    "        return [token.text for token in doc]\n",
    "    \n",
    "    def pad_utterance(self, tokenized_utterance):\n",
    "        \"\"\"\n",
    "        :param utterance: list of string\n",
    "        :param length: desired list length\n",
    "        :return: padded/sliced list\n",
    "        \"\"\"\n",
    "        diff = len(tokenized_utterance) - self.max_tokens\n",
    "        if diff > 0:\n",
    "            return tokenized_utterance[:self.max_tokens]\n",
    "        else:\n",
    "            return tokenized_utterance + [self.pad_char] * -diff\n",
    "\n",
    "    def build_vocab(self, data, depth=1, max_vocab_size=None):\n",
    "        \"\"\"\n",
    "        :param data: list of data\n",
    "        :param depth: depth of data list\n",
    "        :param max_vocab_size:\n",
    "        :return: dict and list mapping data to indices\n",
    "        \"\"\"\n",
    "        if depth >1:\n",
    "            data = list(itertools.chain.from_iterable(data)) # Make list 1D\n",
    "        data_counts = Counter(data)  # Count occurrences of each word in the list\n",
    "\n",
    "        vocabulary_inv = [x[0] for x in data_counts.most_common(max_vocab_size)]\n",
    "        vocabulary = {x: i for i, x in enumerate(vocabulary_inv)}\n",
    "        return vocabulary, vocabulary_inv\n",
    "\n",
    "    def fit(self, utterances, labels):\n",
    "        \"\"\"\n",
    "        :param utterances: list of raw utterances\n",
    "        :param labels: list of raw labels\n",
    "        \"\"\"\n",
    "        split_utterances = [self.split_utterance(utterance) for utterance in utterances]\n",
    "        padded_utterances = [self.pad_utterance(utterance) for utterance in split_utterances]\n",
    "        self.token_to_index, self.index_to_token = self.build_vocab(padded_utterances, depth=2)\n",
    "        self.intent_to_index, self.index_to_intent = self.build_vocab(labels, depth=1)\n",
    "\n",
    "    def transform_utterance(self, utterance):\n",
    "        \"\"\"\n",
    "        :param utterance: raw utterance string\n",
    "        :return: preprocessed utterance\n",
    "        \"\"\"\n",
    "        split_utterance = self.split_utterance(utterance)\n",
    "        padded_utterances = self.pad_utterance(split_utterance)\n",
    "        return [self.token_to_index.get(token, self.unseen_token) for token in padded_utterances]\n",
    "\n",
    "    def transform_label(self, label):\n",
    "        \"\"\"\n",
    "        :param label: raw intent label\n",
    "        :return: indexed intent label\n",
    "        \"\"\"\n",
    "        return self.intent_to_index.get(label, self.unseen_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = TokenPreprocessor(spacy_model='en_core_web_sm')\n",
    "preprocessor.fit(train_df['description'].tolist(), train_df['class'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label to index mappings:\t{'Business': 0, 'Sci/Tech': 1}\n",
      "\n",
      "Token to index mappings:\n",
      "\n",
      "{'the': 0, ',': 1, '-': 2, 'a': 3, 'of': 4, 'to': 5, 'in': 6, '<padded>': 7, \"'s\": 8, 'for': 9, 'Reuters': 10, '.': 11, 'and': 12, ' ': 13, 'as': 14, 'The': 15, 'are': 16, 'on': 17, 'is': 18, 'by': 19, '(': 20, 'has': 21, 'new': 22, ')': 23, 'A': 24, 'it': 25, 'that': 26, 'at': 27, 'Inc.': 28, 'company': 29, 'oil': 30, 'AP': 31, 'with': 32, 'but': 33, 'can': 34, 'Google': 35, 'be': 36, 'its': 37, '--': 38, '?': 39, 'prices': 40, 'over': 41, 'from': 42, 'market': 43, 'about': 44, 'after': 45, 'an': 46, 'more': 47, \"'\": 48, 'economy': 49, 'sales': 50, 'NEW': 51, 'YORK': 52, 'you': 53, 'may': 54, 'their': 55, 'giant': 56, 'quarter': 57, 'will': 58, 'Japanese': 59, 'all': 60, 'service': 61, 'they': 62, 'had': 63, 'said': 64, 'again': 65, 'crude': 66, 'showed': 67, 'could': 68, 'world': 69, 'fell': 70, 'back': 71, 'bit': 72, 'last': 73, 'week': 74, 'After': 75, 'do': 76, 'when': 77, 'should': 78, 'record': 79, 'auction': 80, 'need': 81, 'your': 82, 'interview': 83, 'show': 84, 'down': 85, 'second': 86, 'five': 87, 'An': 88, 'shares': 89, 'search': 90, 'One': 91, 'pay': 92, 'looking': 93, 'than': 94, 'group': 95, 'up': 96, 'Corp.': 97, 'researchers': 98, 'former': 99, 'New': 100, 'what': 101, 'people': 102, 'out': 103, 'best': 104, 'Philippines': 105, 'this': 106, 'business': 107, 'would': 108, 'Short': 109, 'sellers': 110, 'Wall': 111, 'Street': 112, 'ultra': 113, 'seeing': 114, 'firm': 115, 'well': 116, 'Soaring': 117, 'plus': 118, 'outlook': 119, 'stock': 120, 'have': 121, 'main': 122, 'three': 123, 'higher': 124, 'year': 125, 'past': 126, 'retail': 127, 'mutual': 128, '#': 129, 'claims': 130, 'work': 131, 'band': 132, 'worries': 133, 'OPEC': 134, 'highly': 135, 'public': 136, 'Friday': 137, 'U.S.': 138, 'If': 139, 'think': 140, 'little': 141, 'US': 142, 'later': 143, 'growth': 144, 'country': 145, 'spending': 146, 'rates': 147, 'South': 148, 'central': 149, 'bank': 150, 'buying': 151, 'years': 152, 'point': 153, 'bid': 154, 'Hewlett': 155, 'Packard': 156, 'Indian': 157, 'nuclear': 158, 'his': 159, 'million': 160, 'day': 161, 'plans': 162, 'I': 163, 'IBM': 164, 'Even': 165, 'was': 166, 'weapons': 167, 'based': 168, 'technology': 169, 'including': 170, 'Central': 171, 'Square': 172, 'Lynn': 173, 'brighter': 174, 'sidewalks': 175, 'curbs': 176, 'fences': 177, 'lights': 178, 'Winnick': 179, 'chief': 180, 'Global': 181, 'Mr.': 182, 'executive': 183, 'Dell': 184, 'With': 185, 'off': 186, 'Hurricane': 187, 'Charley': 188, 'how': 189, 'where': 190, 'six': 191, 'get': 192, 'bringing': 193, ':': 194, 'customers': 195, 'monkeys': 196, 'Blues': 197, 'life': 198, 'APMF': 199, 'survey': 200, 'Asian': 201, 'just': 202, 'city': 203, 'grew': 204, 'alligators': 205, 'were': 206, 'IT': 207, 'Some': 208, 'such': 209, 'Computer': 210, 'two': 211, 'founders': 212, 'Playboy': 213, 'Apple': 214, 'download': 215, 'British': 216, 'sell': 217, 'low': 218, 'PC': 219, 'Oracle': 220, 'still': 221, 'scientists': 222, 'Russian': 223, 'dwindling\\\\band': 224, 'cynics': 225, 'green': 226, 'Private': 227, 'investment': 228, 'Carlyle': 229, 'Group,\\\\which': 230, 'reputation': 231, 'making': 232, 'timed': 233, 'occasionally\\\\controversial': 234, 'plays': 235, 'worries\\\\about': 236, 'earnings': 237, 'expected': 238, 'to\\\\hang': 239, 'Authorities': 240, 'halted': 241, 'export\\\\flows': 242, 'pipeline': 243, 'southern': 244, 'Iraq': 245, 'after\\\\intelligence': 246, 'rebel': 247, 'militia': 248, 'AFP': 249, 'Tearaway': 250, 'toppling': 251, 'records': 252, 'straining': 253, 'wallets': 254, 'present': 255, 'economic': 256, 'menace': 257, 'barely': 258, 'Stocks': 259, 'ended': 260, 'slightly': 261, 'Friday\\\\but': 262, 'stayed': 263, 'near': 264, 'lows': 265, 'surged': 266, 'Assets': 267, 'nation': 268, 'money': 269, 'funds': 270, '36;1.17': 271, 'billion': 272, 'USATODAY.com': 273, 'Retail': 274, 'bounced': 275, 'July': 276, 'jobless': 277, 'benefits': 278, 'Forbes.com': 279, 'earning': 280, 'PH.D.': 281, 'Sociology': 282, 'Danny': 283, 'Bazil': 284, 'Riley': 285, 'started': 286, 'general': 287, 'manager': 288, 'dwindling': 289, 'TEHRAN': 290, 'nothing': 291, 'douse': 292, 'scorching': 293, 'markets': 294, 'already': 295, 'JAKARTA': 296, 'Non': 297, 'exporters': 298, 'consider': 299, 'increasing': 300, 'output': 301, 'cool': 302, 'WASHINGTON': 303, '/': 304, 'anticipated': 305, 'initial': 306, 'dollar': 307, 'tumbled': 308, 'broadly': 309, 'data': 310, 'showing': 311, 'help': 312, 'elderly': 313, 'relatives': 314, 'finances': 315, \"n't\": 316, 'shy': 317, 'purchasing': 318, 'power': 319, 'kids': 320, 'big': 321, 'part': 322, 'why': 323, 'school': 324, 'season': 325, 'become': 326, 'There': 327, 'cause': 328, 'celebration': 329, 'these': 330, 'days': 331, 'investors': 332, 'value': 333, 'focused': 334, 'trade': 335, 'deficit': 336, 'exploded': 337, '19': 338, '\\\\$55.8bn': 339, 'costs': 340, 'drove': 341, 'imports': 342, 'according': 343, 'Oil': 344, 'Shell': 345, 'bracing': 346, 'itself': 347, 'takeover': 348, 'attempt': 349, 'possibly': 350, 'French': 351, 'rival': 352, 'Total': 353, 'bidding': 354, 'gets': 355, 'underway': 356, 'offering': 357, 'despite': 358, 'minute': 359, 'Official': 360, 'figures': 361, '12-nation': 362, 'eurozone': 363, 'continues': 364, 'grow': 365, 'there': 366, 'warnings': 367, 'slow': 368, 'Economic': 369, 'Japan': 370, 'slows': 371, 'experiences': 372, 'drop': 373, 'domestic': 374, 'corporate': 375, 'Interest': 376, 'trimmed': 377, '7.5': 378, 'African': 379, 'lack': 380, 'warning': 381, 'hits': 382, 'cost': 383, 'both': 384, 'hand': 385, 'cars': 386, 'sharply': 387, 'Korea': 388, 'cuts': 389, 'interest': 390, 'percentage': 391, '3.5': 392, 'drive': 393, 'web': 394, 'engine': 395, 'which': 396, 'floated': 397, 'much': 398, '\\\\$36bn': 399, 'fall': 400, 'disappointing': 401, 'third': 402, 'profits': 403, 'while': 404, 'warns': 405, 'final': 406, 'oldest': 407, 'textile': 408, 'operators': 409, 'Ocean': 410, 'island': 411, 'Mauritius': 412, 'shut': 413, 'seven': 414, 'factories': 415, 'cut': 416, 'Chad': 417, 'asks': 418, 'IMF': 419, 'loan': 420, '100,000': 421, 'refugees': 422, 'conflict': 423, 'torn': 424, 'running': 425, 'plant': 426, 'hit': 427, 'fatal': 428, 'accident': 429, 'close': 430, 'reactors': 431, 'safety': 432, 'checks': 433, 'Trevor': 434, 'Baylis': 435, 'veteran': 436, 'inventor': 437, 'famous': 438, 'creating': 439, 'Freeplay': 440, 'clockwork': 441, 'radio': 442, 'planning': 443, 'float': 444, 'Saudi': 445, 'Arabia': 446, 'says': 447, 'ready': 448, 'push': 449, 'extra': 450, '1.3': 451, 'barrels': 452, 'into': 453, 'led': 454, 'UAE': 455, 'Etisalat': 456, 'spend': 457, '\\\\$1bn': 458, '544': 459, 'm': 460, 'expansion': 461, 'winning': 462, 'Network': 463, 'Rail': 464, 'flies': 465, 'specialist': 466, 'engineers': 467, 'West': 468, 'Coast': 469, 'Mainline': 470, 'because': 471, 'UK': 472, 'skills': 473, 'shortage': 474, 'BEDFORD': 475, 'Scientists': 476, 'NitroMed': 477, 'hope': 478, 'experimental': 479, 'drugs': 480, 'cure': 481, 'heart': 482, 'disease': 483, 'someday': 484, 'But': 485, 'lately': 486, 'focus': 487, \"'ve\": 488, 'submitted': 489, 'my': 490, 'buy': 491, 'computer': 492, 'Massachusetts': 493, 'bargain': 494, 'hunters': 495, 'droves': 496, 'shopped': 497, 'hard': 498, 'yesterday': 499, 'tax': 500, 'holiday': 501, 'everything': 502, 'E': 503, 'mail': 504, 'victim': 505, 'own': 506, 'success': 507, 'That': 508, 'conclusion': 509, 'genius': 510, 'mess': 511, 'Bill': 512, 'Gates': 513, 'brilliant': 514, 'technologist': 515, 'he': 516, 'cofounded': 517, 'Microsoft': 518, 'Target': 519, 'abusers': 520, 'legal': 521, 'We': 522, 'share': 523, 'outrage': 524, 'expressed': 525, 'columnist': 526, 'Steve': 527, 'Bailey': 528, 'President': 529, 'Bush': 530, 'been': 531, 'saying': 532, 'turned': 533, 'corner': 534, 'quot': 535, ';': 536, 'Democratic': 537, 'presidential': 538, 'Marlborough': 539, 'suing': 540, 'employees': 541, 'senior': 542, 'managers': 543, 'allegedly': 544, 'conspiring': 545, 'lawsuit': 546, 'against': 547, 'Gary': 548, 'Crossing': 549, 'refocuses': 550, 'attention': 551, 'knew': 552, 'Russia': 553, 'emerging': 554, 'superpower': 555, 'reason': 556, 'less': 557, 'Kevin': 558, 'B.': 559, 'Rollins': 560, 'talks': 561, 'transitory': 562, 'slip': 563, 'customer': 564, 'cash': 565, 'rich': 566, 'dying': 567, 'wealth': 568, 'Stein': 569, 'proposes': 570, 'Quality': 571, 'Distribution': 572, 'hammered': 573, 'reporting': 574, 'large': 575, 'loss': 576, 'blows': 577, 'house': 578, 'make': 579, 'insurance': 580, 'results': 581, 'not': 582, 'grim': 583, 'tech': 584, 'Just': 585, 'tough': 586, 'Detroit': 587, 'troubled': 588, 'carmaker': 589, 'thanks': 590, 'maverick': 591, 'designer': 592, 'car': 593, 'Americans': 594, 'tricking': 595, 'places': 596, 'swim': 597, 'Here': 598, 'look': 599, 'In': 600, '1993': 601, 'geeks': 602, 'digital': 603, 'nightmare': 604, 'changed': 605, 'culture': 606, 'It': 607, 'far': 608, 'creepier': 609, 'Celebrity': 610, 'fashion': 611, 'booming': 612, 'These': 613, 'webpreneurs': 614, 'street': 615, 'No': 616, 'other': 617, 'recording': 618, 'artist': 619, 'channel': 620, 'American': 621, 'middle': 622, 'class': 623, 'tastes': 624, 'quite': 625, 'like': 626, 'Chip': 627, 'Davis': 628, 'selling': 629, 'Got': 630, 'unique': 631, 'problem': 632, 'Not': 633, 'worry': 634, 'find': 635, 'financial': 636, 'planner': 637, 'every': 638, 'specialized': 639, 'Today': 640, 'increasingly': 641, 'demanding': 642, 'Asia': 643, 'elsewhere': 644, 'Henry': 645, 'Astorga': 646, 'describes': 647, 'Well': 648, 'election': 649, 'time': 650, 'Republic': 651, 'means': 652, 'rolling': 653, 'Why': 654, 'General': 655, 'Motors': 656, 'dropped': 657, 'Oldsmobile': 658, 'four': 659, 'brand': 660, 'paradoxes': 661, 'GM': 662, 'face': 663, 'name': 664, 'Although': 665, 'smattering': 666, 'Chinese': 667, 'Filipinos': 668, 'Indians': 669, 'Thais': 670, 'others': 671, 'crow': 672, 'alive': 673, 'evidenced': 674, 'appreciation': 675, 'Pinoy': 676, 'Globalization': 677, 'does': 678, 'strange': 679, 'things': 680, 'Manila': 681, 'consultant': 682, 'tourism': 683, 'destinations': 684, 'kicked': 685, 'crowded': 686, 'our': 687, 'categories': 688, 'Sense': 689, 'Place': 690, 'York': 691, 'sometimes': 692, 'ornately': 693, 'described': 694, 'albino': 695, 'Do': 696, 'most': 697, 'projects': 698, 'fail': 699, 'number': 700, 'consultancies': 701, 'Services': 702, 'BEA': 703, 'Systems': 704, 'hired': 705, 'Associates': 706, 'International': 707, 'responsible': 708, 'CA': 709, 'Unicenter': 710, 'line': 711, 'enterprise': 712, 'management': 713, 'Autodesk': 714, 'unwrapped': 715, 'updated': 716, 'version': 717, 'hosted': 718, 'project': 719, 'collaboration': 720, 'targeted': 721, 'construction': 722, 'manufacturing': 723, 'LONDON': 724, 'U.K.': 725, 'National': 726, 'Health': 727, 'Service': 728, 'NHS': 729, 'tapped': 730, 'researcher': 731, 'Gartner': 732, 'provide': 733, 'though': 734, 'gave': 735, 'magazine': 736, 'midst': 737, 'IPO': 738, 'filing': 739, 'co': 740, 'due': 741, 'current': 742, 'issue': 743, 'delay': 744, 'music': 745, 'retailer': 746, 'Netherlands': 747, 'beats': 748, 'launching': 749, 'Europe': 750, 'latest': 751, 'battleground': 752, '\\\\$297': 753, 'Also': 754, 'TiVo': 755, 'goes': 756, 'attract': 757, 'Verizon': 758, 'offer': 759, 'act': 760, 'virtual': 761, 'switchboard': 762, 'operator': 763, 'letting': 764, 'stay': 765, 'touch': 766, 'Internet': 767, 'advertising': 768, 'forecast': 769, 'shows': 770, 'slowdown': 771, 'paid': 772, 'listings': 773, 'next': 774, 'Will': 775, 'Blogs': 776, 'hottest': 777, 'thing': 778, 'Net': 779, 'messing': 780, 'traditional': 781, 'publishing': 782, 'principles': 783, 'Was': 784, 'absenteeism': 785, 'high\\\\on': 786, 'Tuesday': 787, 'among': 788, 'guys': 789, 'office': 790, 'EA': 791, 'Sports': 792, 'like\\\\to': 793, 'companies\\\\including': 794, 'Texas': 795, 'Instruments': 796, 'TXN.N': 797, 'STMicroelectronics\\\\(STM.PA': 798, 'Broadcom': 799, 'America': 800, 'Online': 801, 'Thursday': 802, 'it\\\\plans': 803, 'priced': 804, 'targeting': 805, 'income': 806, 'consumer': 807, 'electronics\\\\makers': 808, 'Wednesday': 809, 'approved': 810, 'format': 811, 'new\\\\generation': 812, 'discs': 813, 'mystery': 814, 'went': 815, 'wrong': 816, 'the\\\\software': 817, 'industry': 818, 'late': 819, 'June': 820, 'stalled': 821, 'than\\\\20': 822, 'Norwegian': 823, 'hacker': 824, 'famed': 825, 'developing': 826, 'DVD': 827, 'encryption': 828, 'cracking': 829, 'software': 830, 'apparently': 831, 'struck': 832, '151': 833, 'ability': 834, 'complete\\\\tracks': 835, 'directly': 836, 'cell': 837, 'phone': 838, 'networks': 839, 'mobile': 840, 'phones': 841, 'is\\\\becoming': 842, 'reality': 843, 'TechWeb': 844, 'News': 845, 'August': 846, '13': 847, '2004': 848, 'documents\\\\detailing': 849, 'confidential': 850, 'information': 851, 'which\\\\companies': 852, 'receive': 853, 'discounts': 854, 'software\\\\products': 855, 'World': 856, 'Developers': 857, 'early': 858, 'code': 859, 'operating': 860, 'system': 861, 'skin': 862, 'being': 863, 'crafted': 864, 'MacCentral': 865, 'open': 866, 'store': 867, 'month': 868, 'western': 869, '145-mph': 870, 'force': 871, 'took': 872, 'forecasters': 873, 'surprise': 874, 'shaky': 875, 'science': 876, '4,000': 877, '48': 878, 'Nobel': 879, 'Prize': 880, 'winners': 881, 'having': 882, 'signed': 883, 'statement': 884, 'opposing': 885, 'dormitory': 886, 'converted': 887, 'classrooms': 888, 'Pensacola': 889, 'Naval': 890, 'Air': 891, 'Station': 892, 'dedicated': 893, 'Columbia': 894, 'cargo': 895, 'ship': 896, 'docked': 897, 'international': 898, 'space': 899, 'station': 900, 'Saturday': 901, 'food': 902, 'water': 903, 'fuel': 904, 'Along': 905, 'banks': 906, 'canal': 907, 'women': 908, 'rowboats': 909, 'grill': 910, 'fish': 911, 'fresh': 912, 'bananas': 913, 'Families': 914, 'Tyrannosaurus': 915, 'Rex': 916, 'incredibly': 917, 'fast\\\\during': 918, 'teenaged': 919, 'spurt': 920, 'saw': 921, 'dinosaur': 922, 'expand': 923, 'its\\\\bulk': 924, 'times': 925, 'Procrastinating': 926, 'turned\\\\into': 927, 'workaholics': 928, 'using': 929, 'gene': 930, 'treatment': 931, 'block': 932, 'key': 933, 'brain\\\\compound': 934, 'reported': 935, 'born': 936, 'and\\\\soul': 937, 'party': 938, 'so': 939, 'seems': 940, 'As': 941, 'Shakespeare': 942, 'rose': 943, 'any': 944, 'other\\\\name': 945, 'smell': 946, 'sweet': 947, 'Right': 948, 'Wednesday\\\\they': 949, 'received': 950, 'permission': 951, 'clone': 952, 'human': 953, 'embryos': 954, 'medical\\\\research': 955, 'SPACE.com': 956, 'expedition': 957, 'found': 958, 'evidence': 959, '\\\\': 960, 'alien': 961, 'spaceship': 962, 'something': 963}\n"
     ]
    }
   ],
   "source": [
    "print(\"Label to index mappings:\\t{}\\n\\nToken to index mappings:\\n\\n{}\".\n",
    "      format(preprocessor.intent_to_index, preprocessor.token_to_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The news looks bad today. ==> [15, -1, -1, -1, -1, 11, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7]\n",
      "MXNet is awesome. No really... ==>[-1, 18, -1, 11, 616, -1, -1, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7]\n"
     ]
    }
   ],
   "source": [
    "print(\"The news looks bad today. ==> {}\".format(preprocessor.transform_utterance(\"The news looks bad today.\")))\n",
    "print(\"MXNet is awesome. No really... ==>{}\".format(preprocessor.transform_utterance(\"MXNet is awesome. No really...\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Data Iterators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "import numpy as np\n",
    "\n",
    "X_train = np.array([preprocessor.transform_utterance(utt) for utt in train_df['description'].tolist()])\n",
    "Y_train = np.array([preprocessor.transform_label(label) for label in train_df['class'].tolist()])\n",
    "\n",
    "X_test = np.array([preprocessor.transform_utterance(utt) for utt in test_df['description'].tolist()])\n",
    "Y_test = np.array([preprocessor.transform_label(label) for label in test_df['class'].tolist()])\n",
    "\n",
    "batch_n=3\n",
    "\n",
    "train_iter = mx.io.NDArrayIter(data=X_train, label=Y_train, batch_size=batch_n, shuffle=True)\n",
    "test_iter = mx.io.NDArrayIter(data=X_test, label=Y_test, batch_size=batch_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 0\n",
      "X:\n",
      "[\n",
      "[[171. 172.   6. 173.  78.  36.  93.   3.  72. 174.  11. 100. 175.   1.\n",
      "  176.   1. 177.   1. 178.   1.]\n",
      " [185.   0. 145.   6.  81.   4. 565.  12. 566. 102. 567.   5.  84. 186.\n",
      "   55. 568.   1. 182. 569. 570.]\n",
      " [163. 204.  96.   6. 100. 691.   1. 190.  56. 205.  38. 692.  47. 693.\n",
      "  694.  14. 695. 205.  38. 206.]]\n",
      "<NDArray 3x20 @cpu(0)>]\n",
      " Y:\n",
      "[\n",
      "[0. 0. 0.]\n",
      "<NDArray 3 @cpu(0)>]\n",
      "\n",
      "Batch 1\n",
      "X:\n",
      "[\n",
      "[[724.  38.  15. 725.   8. 726. 727. 728.  20. 729.  23.  21. 730. 207.\n",
      "  731. 732.  28.   5. 733.  43.]\n",
      " [165. 734.  35.   8. 211. 212. 735.  46.  83.   5. 213. 736.   6.   0.\n",
      "  737.   4.  37. 738. 739.   1.]\n",
      " [ 13.  51.  52.  20.  10.  23.   2.  15. 307. 308. 309.  17. 137.  13.\n",
      "   45. 310. 311.   3.  79. 138.]]\n",
      "<NDArray 3x20 @cpu(0)>]\n",
      " Y:\n",
      "[\n",
      "[0. 0. 0.]\n",
      "<NDArray 3 @cpu(0)>]\n",
      "\n",
      "Batch 2\n",
      "X:\n",
      "[\n",
      "[[ 31.   2. 187. 188.   8. 870. 871. 872. 873.  19. 874.  12.  67. 202.\n",
      "  189. 875.   3. 876.  25. 221.]\n",
      " [ 91.   4.   0. 407. 408. 409.  17.   0. 157. 410. 411.   4. 412.  73.\n",
      "   74. 413. 414. 415.  12. 416.]\n",
      " [ 10.   2. 109.   2. 110.   1. 111. 112.   8. 224.   4. 113.   2. 225.\n",
      "    1.  16. 114. 226.  65.  11.]]\n",
      "<NDArray 3x20 @cpu(0)>]\n",
      " Y:\n",
      "[\n",
      "[1. 0. 0.]\n",
      "<NDArray 3 @cpu(0)>]\n",
      "\n",
      "Batch 3\n",
      "X:\n",
      "[\n",
      "[[ 10.   2. 208. 102.  16. 936.   5.  36.   0. 198. 937.   4.   0. 938.\n",
      "   38.  12. 939.  25. 940.  16.]\n",
      " [ 10.   2. 800. 801.  17. 802.  64. 803.   5. 217.   3. 218.   2. 804.\n",
      "  219. 805. 218.   2. 806.  12.]\n",
      " [956.   2.  88. 957.   4. 223.  98. 130.   5. 121. 958. 959.  26.  46.\n",
      "  960.  13. 961. 962.  63. 963.]]\n",
      "<NDArray 3x20 @cpu(0)>]\n",
      " Y:\n",
      "[\n",
      "[1. 1. 1.]\n",
      "<NDArray 3 @cpu(0)>]\n",
      "\n",
      "Batch 4\n",
      "X:\n",
      "[\n",
      "[[ 15. 383.   4. 151. 384.  22.  12.  86. 385. 386.  70. 387.  41.   0.\n",
      "  126.  87. 152.   1.   3.  22.]\n",
      " [249.   2. 250.  69.  30.  40.   1. 251. 252.  12. 253. 254.   1. 255.\n",
      "    3.  22. 256. 257. 258. 123.]\n",
      " [ 10.   2.  24.  95.   4. 169. 794. 795. 796.  28.  20. 797.  23.   1.\n",
      "  798.  23.  12. 799.  97.  20.]]\n",
      "<NDArray 3x20 @cpu(0)>]\n",
      " Y:\n",
      "[\n",
      "[0. 0. 1.]\n",
      "<NDArray 3 @cpu(0)>]\n",
      "\n",
      "Batch 5\n",
      "X:\n",
      "[\n",
      "[[600. 601. 191. 602.  63.   3. 603. 604.  26. 605.   0. 606.  11. 607.\n",
      "    8.  44.   5. 192. 608. 609.]\n",
      " [ 15. 197.  18. 673.  12. 116.   6.   0. 105.   1.  14. 674.  19. 106.\n",
      "  675.   4.   0. 676. 197. 132.]\n",
      " [ 10.   2. 216. 222.  64.  17. 949.  63. 950. 951.   5. 952. 953. 954.\n",
      "    9. 955.   1.   6. 101.  62.]]\n",
      "<NDArray 3x20 @cpu(0)>]\n",
      " Y:\n",
      "[\n",
      "[0. 0. 1.]\n",
      "<NDArray 3 @cpu(0)>]\n",
      "\n",
      "Batch 6\n",
      "X:\n",
      "[\n",
      "[[610. 611.  18. 612.  11. 613. 614.  16. 193.  25.   5. 122. 615.   7.\n",
      "    7.   7.   7.   7.   7.   7.]\n",
      " [279.   2.  75. 280.   3. 281.   6. 282.   1. 283. 284. 285. 286.   5.\n",
      "  131.  14.   0. 287. 288.  27.]\n",
      " [ 10.   2. 941. 942.  64.   1.   3. 943.  19. 944. 945. 108. 946.  14.\n",
      "  947.  11. 948.  39.   7.   7.]]\n",
      "<NDArray 3x20 @cpu(0)>]\n",
      " Y:\n",
      "[\n",
      "[0. 0. 1.]\n",
      "<NDArray 3 @cpu(0)>]\n",
      "\n",
      "Batch 7\n",
      "X:\n",
      "[\n",
      "[[ 31.   2. 905.   0. 906.   4.   0. 907.   1. 908.   6. 909. 910. 911.\n",
      "   12. 217. 912. 913.  11. 914.]\n",
      " [434. 435.   1.   0. 436. 437. 438.   9. 439.   0. 440. 441. 442.   1.\n",
      "   18. 443.   5. 444. 159.  29.]\n",
      " [171. 172.   6. 173.  78.  36.  93.   3.  72. 174.  11. 100. 175.   1.\n",
      "  176.   1. 177.   1. 178.   1.]]\n",
      "<NDArray 3x20 @cpu(0)>]\n",
      " Y:\n",
      "[\n",
      "[1. 0. 0.]\n",
      "<NDArray 3 @cpu(0)>]\n",
      "\n",
      "Batch 8\n",
      "X:\n",
      "[\n",
      "[[360. 361.  84.   0. 362. 363.  49. 364.   5. 365.   1.  33. 366.  16.\n",
      "  367.  25.  54. 368.  85. 143.]\n",
      " [ 88.  83.  32.  35.   8. 740.   2. 212. 741. 103.   6.   0. 742. 743.\n",
      "    4. 213.  54. 744.   0.  29.]\n",
      " [ 31.   2. 185.  47.  94. 877. 222.   1. 170. 878. 879. 880. 881.   1.\n",
      "  882. 883.   3. 884. 885.   0.]]\n",
      "<NDArray 3x20 @cpu(0)>]\n",
      " Y:\n",
      "[\n",
      "[0. 0. 1.]\n",
      "<NDArray 3 @cpu(0)>]\n",
      "\n",
      "Batch 9\n",
      "X:\n",
      "[\n",
      "[[ 24.  22. 767. 768. 769. 770.   3. 771.   6. 772.  90. 773.   6.   0.\n",
      "  774.  87. 152.  11. 775.   0.]\n",
      " [630.   3. 631. 632.  39. 633.   5. 634. 194.  53.  34. 635.   3. 636.\n",
      "  637.   9. 638. 639.  81.   7.]\n",
      " [ 10.   2. 227. 228. 115. 229. 230.  21.   3. 231.   9. 232. 116.   2.\n",
      "  233.  12. 234. 235.   6.   0.]]\n",
      "<NDArray 3x20 @cpu(0)>]\n",
      " Y:\n",
      "[\n",
      "[0. 0. 0.]\n",
      "<NDArray 3 @cpu(0)>]\n",
      "\n",
      "Batch 10\n",
      "X:\n",
      "[\n",
      "[[571. 572.  18. 573.  45. 574.   3. 575. 576.   9.   0.  86.  57.  11.\n",
      "    7.   7.   7.   7.   7.   7.]\n",
      " [ 24. 546. 547. 548. 179.   1.   0.  99. 180.   4. 181. 549.   1. 550.\n",
      "  551.  17. 101. 182. 179. 552.]\n",
      " [ 13. 303. 304.  51.  52.  20.  10.  23.   2.  15.  80.   9.  35.  13.\n",
      "   28.   8. 135. 305. 306. 136.]]\n",
      "<NDArray 3x20 @cpu(0)>]\n",
      " Y:\n",
      "[\n",
      "[0. 0. 0.]\n",
      "<NDArray 3 @cpu(0)>]\n",
      "\n",
      "Batch 11\n",
      "X:\n",
      "[\n",
      "[[ 91.   4. 687.  22. 688.   6.   0. 199. 689.   4. 690. 200.  18.   9.\n",
      "  104. 201. 107. 203.  11.  75.]\n",
      " [ 13. 290.  20.  10.  23.   2. 134.  34.  76. 291.   5. 292. 293.  13.\n",
      "   30.  40.  77. 294.  16. 295.]\n",
      " [344.  56. 345.  68.  36. 346. 347.   9.   3. 348. 349.   1. 350.  42.\n",
      "  351. 352. 353.   1.   3.  13.]]\n",
      "<NDArray 3x20 @cpu(0)>]\n",
      " Y:\n",
      "[\n",
      "[0. 0. 0.]\n",
      "<NDArray 3 @cpu(0)>]\n",
      "\n",
      "Batch 12\n",
      "X:\n",
      "[\n",
      "[[ 13. 296.  20.  10.  23.   2. 297.   2. 134.  30. 298.  78. 299.  13.\n",
      "  300. 301.   5. 302.  79.  66.]\n",
      " [714.  13. 106.  74. 715.  46. 716. 717.   4.  37. 718. 719. 720.  61.\n",
      "  721.  27.   0. 722.  12. 723.]\n",
      " [493. 494. 495.  67.  96.   6. 496.  12. 497. 498.  17. 499.   8.  50.\n",
      "  500. 501.   1. 151. 502.  42.]]\n",
      "<NDArray 3x20 @cpu(0)>]\n",
      " Y:\n",
      "[\n",
      "[0. 0. 0.]\n",
      "<NDArray 3 @cpu(0)>]\n",
      "\n",
      "Batch 13\n",
      "X:\n",
      "[\n",
      "[[ 15.  29. 425.   0.  59. 158. 426. 427.  19.   3. 428. 429.  18.   5.\n",
      "  430.  37. 431.   9. 432. 433.]\n",
      " [ 31.   2.  24. 223. 895. 896. 897.  32.   0. 898. 899. 900. 901.   1.\n",
      "  193. 902.   1. 903.   1. 904.]\n",
      " [ 15.  22. 199. 200.   4.   0. 104. 201. 683. 684.  21. 202. 685. 186.\n",
      "    1.  33.  25.   8. 686.  27.]]\n",
      "<NDArray 3x20 @cpu(0)>]\n",
      " Y:\n",
      "[\n",
      "[0. 1. 0.]\n",
      "<NDArray 3 @cpu(0)>]\n",
      "\n",
      "Batch 14\n",
      "X:\n",
      "[\n",
      "[[776.  16.   0. 777. 778.  17.   0. 779.   1.  33.  16.  62. 780.  32.\n",
      "  781. 782. 783.  39.  91.   4.]\n",
      " [139.  53. 140.  53.  54.  81.   5. 312.  82. 313. 314.  32.  55. 315.\n",
      "    1.  76. 316.  36. 317.  44.]\n",
      " [ 10.   2. 915. 916. 204. 917. 918.   3. 919. 144. 920.  26. 921.   0.\n",
      "  922. 923. 924.  19. 191. 925.]]\n",
      "<NDArray 3x20 @cpu(0)>]\n",
      " Y:\n",
      "[\n",
      "[0. 0. 1.]\n",
      "<NDArray 3 @cpu(0)>]\n",
      "\n",
      "Batch 15\n",
      "X:\n",
      "[\n",
      "[[ 24. 745. 746.  42.   0. 747. 748. 214.  19. 749.   3. 215.  61.   6.\n",
      "  750.   8. 751.  43. 752.  11.]\n",
      " [ 13.  51.  52.  20.  10.  23.   2. 117.  66.  40. 118. 133.  13.  44.\n",
      "    0.  49.  12.   0. 119.   9.]\n",
      " [558. 559. 560.   1.   0.  22. 180. 183.   4. 184.   1. 561.  44. 184.\n",
      "    8. 562. 563.   6. 564.  61.]]\n",
      "<NDArray 3x20 @cpu(0)>]\n",
      " Y:\n",
      "[\n",
      "[0. 0. 0.]\n",
      "<NDArray 3 @cpu(0)>]\n",
      "\n",
      "Batch 16\n",
      "X:\n",
      "[\n",
      "[[417. 418.   0. 419.   9.   3. 420.   5.  92.   9.  93.  45.  47.  94.\n",
      "  421. 422.  42. 423.   2. 424.]\n",
      " [844.   2. 845.   2. 846. 847.   1. 848.   7.   7.   7.   7.   7.   7.\n",
      "    7.   7.   7.   7.   7.   7.]\n",
      " [ 15. 142. 335. 336.  21. 337. 338.   5.   3.  79. 339.  14.  30. 340.\n",
      "  341. 342. 124.   1. 343.   5.]]\n",
      "<NDArray 3x20 @cpu(0)>]\n",
      " Y:\n",
      "[\n",
      "[0. 1. 0.]\n",
      "<NDArray 3 @cpu(0)>]\n",
      "\n",
      "Batch 17\n",
      "X:\n",
      "[\n",
      "[[ 31.   2. 267.   4.   0. 268.   8. 127. 269.  43. 128. 270.  70.  19.\n",
      "   13. 129. 271. 272.   6.   0.]\n",
      " [519.   0. 520.   4. 521. 167. 522.  34.  60. 523.   0. 524.   1. 525.\n",
      "   19. 526. 527. 528.  20.  48.]\n",
      " [ 10.   2. 240. 121. 241.  30. 242.  42.   0. 122. 243.   6. 244. 245.\n",
      "  246.  67.   3. 247. 248.  68.]]\n",
      "<NDArray 3x20 @cpu(0)>]\n",
      " Y:\n",
      "[\n",
      "[0. 0. 0.]\n",
      "<NDArray 3 @cpu(0)>]\n",
      "\n",
      "Batch 18\n",
      "X:\n",
      "[\n",
      "[[503.   2. 504.  18.   3. 505.   4.  37. 506. 507.  11. 508.   8.   0.\n",
      "  509.   4. 164.  97.  98.   6.]\n",
      " [648.   1.  25.   8. 649. 650.   6.   0. 651.   4.   0. 105.   1.  12.\n",
      "   26. 652.   0. 196.  16. 653.]\n",
      " [ 15. 354. 355. 356.   9.  35.   8. 136. 357.   1. 358.  73.   2. 359.\n",
      "  133.  41.  46.  83.  32.  37.]]\n",
      "<NDArray 3x20 @cpu(0)>]\n",
      " Y:\n",
      "[\n",
      "[0. 0. 0.]\n",
      "<NDArray 3 @cpu(0)>]\n",
      "\n",
      "Batch 19\n",
      "X:\n",
      "[\n",
      "[[463. 464. 465.   6. 466. 157. 467.   5. 131.  17.   0. 468. 469. 470.\n",
      "  471.   4.   3. 472. 473. 474.]\n",
      " [ 15.  29.   8. 581.  84.  26.  25.   8. 582. 583.  60.  41. 584.  69.\n",
      "   11. 585.  60.   4.  25.  26.]\n",
      " [654. 655. 656. 657.   0. 658.  11.  15. 659. 660.  13. 661. 662.  63.\n",
      "    5. 663.   2.   0. 664.   1.]]\n",
      "<NDArray 3x20 @cpu(0)>]\n",
      " Y:\n",
      "[\n",
      "[0. 0. 0.]\n",
      "<NDArray 3 @cpu(0)>]\n",
      "\n",
      "Batch 20\n",
      "X:\n",
      "[\n",
      "[[665.   3. 666.   4. 667.   1. 668.   1.  59.   1. 669.   1. 670.   1.\n",
      "   12. 671.  54. 672.  44. 114.]\n",
      " [ 13.  51.  52.  20.  10.  23.   2. 109.   2. 110.   1. 111. 112.   8.\n",
      "  289.  13. 132.   4. 113.   2.]\n",
      " [369. 144.   6. 370. 371.  85.  14.   0. 145. 372.   3. 373.   6. 374.\n",
      "   12. 375. 146.  11.   7.   7.]]\n",
      "<NDArray 3x20 @cpu(0)>]\n",
      " Y:\n",
      "[\n",
      "[0. 0. 0.]\n",
      "<NDArray 3 @cpu(0)>]\n",
      "\n",
      "Batch 21\n",
      "X:\n",
      "[\n",
      "[[ 10.   2.  24.  95.   4. 807. 808.  64.  17. 809.  62. 810.   0. 811.\n",
      "    9.   3. 812.   4. 813.  26.]\n",
      " [ 31.   2.  24.  99. 886. 887.   5. 888.  27.   0. 889. 890. 891. 892.\n",
      "  166. 893. 137.   5. 211. 894.]\n",
      " [ 24.  95. 454.  19.   0. 455.   8. 456. 162.   5. 457. 458.  20. 459.\n",
      "  460.  23.  17. 461.  45. 462.]]\n",
      "<NDArray 3x20 @cpu(0)>]\n",
      " Y:\n",
      "[\n",
      "[1. 1. 0.]\n",
      "<NDArray 3 @cpu(0)>]\n",
      "\n",
      "Batch 22\n",
      "X:\n",
      "[\n",
      "[[553.  18.  65. 554.  14.   3. 555.   2.  33.   0. 556.  21. 557.   5.\n",
      "   76.  32. 158. 167.  94.  32.]\n",
      " [ 10.   2. 259. 260. 261. 124.  17. 262. 263. 264. 265.   9.   0. 125.\n",
      "   14.  30.  40. 266. 126.  13.]\n",
      " [163. 488. 489. 490. 154.   5. 491.  89.   4.  35.  28.   6.   0. 492.\n",
      "   90.  29.   8.  56.  80.   2.]]\n",
      "<NDArray 3x20 @cpu(0)>]\n",
      " Y:\n",
      "[\n",
      "[0. 0. 0.]\n",
      "<NDArray 3 @cpu(0)>]\n",
      "\n",
      "Batch 23\n",
      "X:\n",
      "[\n",
      "[[696. 697. 207. 698. 699.  39. 208. 153.   5.   0. 700.   4.  56. 701.\n",
      "  209.  14. 164. 181. 702.   1.]\n",
      " [ 88.  80.   4.  89.   6.  35.   1.   0. 394.  90. 395. 396.  68.  36.\n",
      "  397.   9.  14. 398.  14. 399.]\n",
      " [ 10.   2.  15. 814.   4. 101. 815. 816.   9. 817. 818.   6. 819. 820.\n",
      "   77.  50. 821.  27.  47. 822.]]\n",
      "<NDArray 3x20 @cpu(0)>]\n",
      " Y:\n",
      "[\n",
      "[0. 0. 1.]\n",
      "<NDArray 3 @cpu(0)>]\n",
      "\n",
      "Batch 24\n",
      "X:\n",
      "[\n",
      "[[155.   2. 156.  89. 400.  45. 401. 402.   2.  57. 403.   1. 404.   0.\n",
      "  115. 405.   0. 406.  57.  58.]\n",
      " [376. 147.  16. 377.   5. 378.  19.   0. 148. 379. 149. 150.   1.  13.\n",
      "   33.   0. 380.   4. 381. 382.]\n",
      " [ 10.   2. 784. 785.   3. 141. 786. 787. 788.   0. 789.  27.   0. 790.\n",
      "   39. 791. 792. 108. 793. 140.]]\n",
      "<NDArray 3x20 @cpu(0)>]\n",
      " Y:\n",
      "[\n",
      "[0. 0. 1.]\n",
      "<NDArray 3 @cpu(0)>]\n",
      "\n",
      "Batch 25\n",
      "X:\n",
      "[\n",
      "[[594.  16. 146.  47.  17. 595. 103.   0. 596. 190.  62. 597.  11. 598.\n",
      "    8.   3. 599.  27.   0.  22.]\n",
      " [139. 187. 188. 577.  82. 578.  85.   1. 189.  34.  53. 579.  82. 580.\n",
      "   29.  92.  39.   7.   7.   7.]\n",
      " [ 10.   2. 117.  66.  40. 118. 236.   0.  49.  12.   0. 119.   9. 237.\n",
      "   16. 238. 239.  41.   0. 120.]]\n",
      "<NDArray 3x20 @cpu(0)>]\n",
      " Y:\n",
      "[\n",
      "[0. 0. 0.]\n",
      "<NDArray 3 @cpu(0)>]\n",
      "\n",
      "Batch 26\n",
      "X:\n",
      "[\n",
      "[[758. 162.   5. 759.   3.  61.  26. 108. 760.  14.   3. 761. 762. 763.\n",
      "    1. 764. 195. 765.   6. 766.]\n",
      " [ 31.   2.  15. 823. 824. 825.   9. 826. 827. 828.   2. 829. 830.  21.\n",
      "  831. 832.  65.  13. 129. 833.]\n",
      " [865.   2. 214. 210.  28.  58. 866.  37.  86.  59. 127. 867. 143. 106.\n",
      "  868.   6.   0. 869.  59. 203.]]\n",
      "<NDArray 3x20 @cpu(0)>]\n",
      " Y:\n",
      "[\n",
      "[0. 1. 1.]\n",
      "<NDArray 3 @cpu(0)>]\n",
      "\n",
      "Batch 27\n",
      "X:\n",
      "[\n",
      "[[ 10.   2. 926. 196. 206. 927. 928. 929.   3. 930. 931.   5. 932.   3.\n",
      "  933. 934.   1. 138.  98. 935.]\n",
      " [616. 617. 618. 619.  34. 620. 621. 622.   2. 623. 624. 625. 626. 627.\n",
      "  628.  12. 159. 104.   2. 629.]\n",
      " [ 10.   2. 220.  97.  50. 849. 135. 850. 851.   1. 209.  14. 852. 853.\n",
      "  854.  17. 220.   8. 107. 855.]]\n",
      "<NDArray 3x20 @cpu(0)>]\n",
      " Y:\n",
      "[\n",
      "[1. 0. 1.]\n",
      "<NDArray 3 @cpu(0)>]\n",
      "\n",
      "Batch 28\n",
      "X:\n",
      "[\n",
      "[[475.  38. 476.  27. 477.  28. 478.  55. 479. 480.  58. 481. 482. 483.\n",
      "  484.  11. 485. 486.  55. 487.]\n",
      " [ 75.   3. 586. 125.   1. 587.   8. 588. 589.  18.  71.  38. 590.   5.\n",
      "    3. 591. 592.  12.   3. 593.]\n",
      " [273.   2. 274.  50. 275.  71.   3.  72.   6. 276.   1.  12.  22. 130.\n",
      "    9. 277. 278.  70.  73.  74.]]\n",
      "<NDArray 3x20 @cpu(0)>]\n",
      " Y:\n",
      "[\n",
      "[0. 0. 0.]\n",
      "<NDArray 3 @cpu(0)>]\n",
      "\n",
      "Batch 29\n",
      "X:\n",
      "[\n",
      "[[165.   3. 510.  34. 511.  96.  11. 512. 513. 166.   3. 514. 515.  77.\n",
      "  516. 517. 518.   1.  33.  14.]\n",
      " [703. 704.  28.  21. 705.   0. 210. 706. 707.  28. 183. 708.   9. 709.\n",
      "    8. 710. 711.   4. 712. 713.]\n",
      " [640.   8. 195.  16. 641. 642.   1.   6. 643.  14. 644.   6.   0.  69.\n",
      "   11.  13. 645. 646. 647.   0.]]\n",
      "<NDArray 3x20 @cpu(0)>]\n",
      " Y:\n",
      "[\n",
      "[0. 0. 0.]\n",
      "<NDArray 3 @cpu(0)>]\n",
      "\n",
      "Batch 30\n",
      "X:\n",
      "[\n",
      "[[529. 530.  21. 531. 532.  26.   0. 142.  49.  21.  48.  48. 533.   0.\n",
      "  534.  11. 535. 536. 537. 538.]\n",
      " [148. 388.   8. 149. 150. 389. 390. 147.  19.   3.  57. 391. 153.   5.\n",
      "  392.   6.   3. 154.   5. 393.]\n",
      " [ 24. 539.   2. 168. 169.  29.  18. 540.  87.  99. 541.   1. 170. 123.\n",
      "  542. 543.   1.   9. 544. 545.]]\n",
      "<NDArray 3x20 @cpu(0)>]\n",
      " Y:\n",
      "[\n",
      "[0. 0. 0.]\n",
      "<NDArray 3 @cpu(0)>]\n",
      "\n",
      "Batch 31\n",
      "X:\n",
      "[\n",
      "[[155.   2. 156.  58.  92. 753. 160.   9.   0. 216.  29.  11. 754. 194.\n",
      "  755. 756.  60. 103.   5. 757.]\n",
      " [ 10.   2.  15. 834.   5. 215. 835. 836.  41. 837.   2. 838. 839.   5.\n",
      "  840. 841. 842.   3. 843.   6.]\n",
      " [677. 678. 679. 680.   5. 102.  11.  24. 161.   6.   0. 198.   4.   3.\n",
      "  681. 105. 168. 107. 682.   2.]]\n",
      "<NDArray 3x20 @cpu(0)>]\n",
      " Y:\n",
      "[\n",
      "[0. 1. 0.]\n",
      "<NDArray 3 @cpu(0)>]\n",
      "\n",
      "Batch 32\n",
      "X:\n",
      "[\n",
      "[[445. 446. 447.  25.  18. 448.   5. 449.  46. 450. 451. 160. 452.   3.\n",
      "  161.   4.  30. 453.   0.  43.]\n",
      " [ 15. 318. 319.   4. 320.  18.   3. 321. 322.   4. 323.   0.  71.   2.\n",
      "    5.   2. 324. 325.  21. 326.]\n",
      " [327.  18. 141. 328.   9. 329.   6.   0. 120.  43. 330. 331.   1.  33.\n",
      "  332.   6. 333.   2. 334. 128.]]\n",
      "<NDArray 3x20 @cpu(0)>]\n",
      " Y:\n",
      "[\n",
      "[0. 0. 0.]\n",
      "<NDArray 3 @cpu(0)>]\n",
      "\n",
      "Batch 33\n",
      "X:\n",
      "[\n",
      "[[219. 856.   2. 857. 192. 858. 859.   9.  22. 860. 861.  48. 862.  48.\n",
      "  221. 863. 864.  11.   7.   7.]\n",
      " [171. 172.   6. 173.  78.  36.  93.   3.  72. 174.  11. 100. 175.   1.\n",
      "  176.   1. 177.   1. 178.   1.]\n",
      " [185.   0. 145.   6.  81.   4. 565.  12. 566. 102. 567.   5.  84. 186.\n",
      "   55. 568.   1. 182. 569. 570.]]\n",
      "<NDArray 3x20 @cpu(0)>]\n",
      " Y:\n",
      "[\n",
      "[1. 0. 0.]\n",
      "<NDArray 3 @cpu(0)>]\n"
     ]
    }
   ],
   "source": [
    "train_iter.reset()\n",
    "for i, batch in enumerate(train_iter):\n",
    "    print(\"\\nBatch {}\\nX:\\n{}\\n Y:\\n{}\".format(i, batch.data, batch.label))\n",
    "train_iter.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the model symbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sym_gen(sentence_size, num_embed, vocab_size, num_label=2, filter_list=[3, 4, 5], num_filter=100, dropout=0.0):\n",
    "    \n",
    "    input_x = mx.sym.Variable('data')\n",
    "    input_y = mx.sym.Variable('softmax_label')\n",
    "    \n",
    "    X_shape = (120,20)\n",
    "\n",
    "    # embedding layer\n",
    "    embed_layer = mx.sym.Embedding(data=input_x, input_dim=vocab_size, output_dim=num_embed)\n",
    "    print(\"Embed output shape: {}\".format(embed_layer.infer_shape(data=X_shape)[1][0]))\n",
    "    conv_input = mx.sym.reshape(data=embed_layer, shape=(0, 1, sentence_size, num_embed))\n",
    "    print(\"Convolutional input shape: {}\".format(conv_input.infer_shape(data=X_shape)[1][0]))\n",
    "\n",
    "    # create convolution + (max) pooling layer for each filter operation\n",
    "    pooled_outputs = []\n",
    "    for i, filter_size in enumerate(filter_list):\n",
    "        convi = mx.sym.Convolution(data=conv_input, kernel=(filter_size, num_embed), num_filter=num_filter)\n",
    "        relui = mx.sym.Activation(data=convi, act_type='relu')\n",
    "        pooli = mx.sym.Pooling(data=relui, pool_type='max', kernel=(sentence_size - filter_size + 1, 1), stride=(1,1))\n",
    "        pooled_outputs.append(pooli)\n",
    "\n",
    "    # combine all pooled outputs\n",
    "    concat = mx.sym.Concat(*pooled_outputs, dim=1)\n",
    "    print(\"Pooled output shape: {}\".format(concat.infer_shape(data=X_shape)[1][0]))\n",
    "    h_pool = mx.sym.reshape(data=concat, shape=(0, -1))\n",
    "    print(\"Reshaped pooled output shape: {}\".format(h_pool.infer_shape(data=X_shape)[1][0]))\n",
    "    \n",
    "    # dropout layer\n",
    "    h_drop = mx.sym.Dropout(data=h_pool, p=dropout)\n",
    "\n",
    "    fc = mx.sym.FullyConnected(data=h_drop, num_hidden=num_label)\n",
    "\n",
    "    # softmax output\n",
    "    sm = mx.sym.SoftmaxOutput(data=fc, label=input_y, name='softmax')\n",
    "\n",
    "    return sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embed output shape: (120, 20, 16)\n",
      "Convolutional input shape: (120, 1, 20, 16)\n",
      "Pooled output shape: (120, 300, 1, 1)\n",
      "Reshaped pooled output shape: (120, 300)\n"
     ]
    }
   ],
   "source": [
    "symbol = sym_gen(20, 16, 1600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "module = mx.module.Module(symbol)\n",
    "\n",
    "module.fit(train_data = train_iter,\n",
    "           eval_data = test_iter,\n",
    "           eval_metric = 'acc',\n",
    "           optimizer = 'Adam',\n",
    "           optimizer_params = {'learning_rate': 0.01},\n",
    "           initializer = mx.initializer.Uniform(0.1),\n",
    "           num_epoch = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# View Training Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct Model Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3_mxnet",
   "language": "python",
   "name": "python3_mxnet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
